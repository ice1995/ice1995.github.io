<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[python通过boost.python使用c/c++]]></title>
    <url>%2F2020%2F01%2F15%2Fpythonwithc-1%2F</url>
    <content type="text"><![CDATA[安装boost环境https://www.boost.org/下载，解压设置环境变量即可在c/c++中日常使用但是对于boost.python来说需要对boost进行编译 编写user-config.jam文件，设置python目录、链接文件目录、头文件目录，位于c:/users/用户/user-config.jam 12345678import toolset : using ;using python: 3.7: D:/Applications/python/python37/python.exe : D:/Applications/python/python37/include: D:/Applications/python/python37/libs: &lt;toolset&gt;gcc; 12bootstrap.bat gcc #生成b2.exe等文件b2 --with-python --toolset=gcc architecture=x86 address-model=64 link=shared #在stage/lib下生成boost.python的对应Python版本的dll和dll.a文件 编写并编译c++程序使用boost.python导出需要使用的c++模块，使用说明见https://wiki.python.org/moin/boost.python/module需要注意的是，BOOST_PYTHON_MODULE(my_module)中的my_module必须和文件名相同编译c++程序生成dll文件 python使用c++编译后的dll文件将使用boost.python的dll文件改名为pyd（python的链接库文件）在Python中添加路径（可以使用sys.path.append或者复制到python执行目录下） ，需要注意，除了添加.pyd文件之外，还需要添加 boost.python的对应Python版本的dll文件 1import my_module]]></content>
      <categories>
        <category>c/c++</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>c/c++</tag>
        <tag>boost</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将项目发布到maven过程记录]]></title>
    <url>%2F2020%2F01%2F08%2Fpush2maven%2F</url>
    <content type="text"><![CDATA[说明&emsp;&emsp;用于记录将自己的项目发布到maven中央仓库的过程。 记录 注册sonatype账号：【申请上传资格】注册地址:https://issues.sonatype.org/secure/Signup!default.jspa 登录sonatype并初始化 新建issue并解决提出的问题如：https://issues.sonatype.org/browse/OSSRH-54353 创建密钥并发布 安装gpg，新建密钥对（输入账号、邮箱、密码），发布密钥到服务服务端 1234567# 列出密钥gpg --list-keysgpg --keyserver http://keyserver.ubuntu.com:11371 --send-keys key_idgpg --keyserver http://pool.sks-keyservers.net:11371 --send-keys key_idgpg --keyserver http://keyserver.ubuntu.com:11371 --send-keys key_idgpg --keyserver http://keys.gnupg.net:11371 --send-keys key_idgpg --keyserver http://keys.openpgp.org:11371 --send-keys key_id 配置maven 修改setting.xml 12345&lt;server&gt; &lt;id&gt;ossrh&lt;/id&gt; &lt;username&gt;sonatype用户名&lt;/username&gt; &lt;password&gt;sonatype密码&lt;/password&gt; &lt;/server&gt; 修改项目pom.xml 注意：snapshotRepository节点和repository节点的id要和上面server配置的id一致 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122&lt;!--&gt;项目的协议&lt;--&gt;&lt;licenses&gt; &lt;license&gt; &lt;name&gt;The Apache Software License, Version 2.0&lt;/name&gt; &lt;url&gt;http://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;distribution&gt;actable&lt;/distribution&gt; &lt;/license&gt;&lt;/licenses&gt;&lt;!--&gt;开发者的信息&lt;--&gt;&lt;developers&gt; &lt;developer&gt; &lt;name&gt;example&lt;/name&gt; &lt;email&gt;example@outlook.com&lt;/email&gt; &lt;/developer&gt;&lt;/developers&gt;&lt;!--&gt;项目的版本管理地址&lt;--&gt;&lt;scm&gt; &lt;url&gt;https://github.com/Bpazy/Id&lt;/url&gt;&lt;/scm&gt;&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;release&lt;/id&gt; &lt;properties&gt; &lt;profile.env&gt;prod&lt;/profile.env&gt; &lt;/properties&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;plugins&gt; &lt;!-- Source --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar-no-fork&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- Javadoc --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;version&gt;2.9.1&lt;/version&gt; &lt;configuration&gt; &lt;show&gt;private&lt;/show&gt; &lt;nohelp&gt;true&lt;/nohelp&gt; &lt;charset&gt;UTF-8&lt;/charset&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;docencoding&gt;UTF-8&lt;/docencoding&gt; &lt;additionalparam&gt;-Xdoclint:none&lt;/additionalparam&gt; &lt;!-- TODO 临时解决不规范的javadoc生成报错,后面要规范化后把这行去掉 --&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!-- GPG --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-gpg-plugin&lt;/artifactId&gt; &lt;version&gt;1.5&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;verify&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;sign&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!--Compiler --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;verbose&gt;true&lt;/verbose&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;showWarnings&gt;false&lt;/showWarnings&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!--Release --&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-release-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.3&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;distributionManagement&gt; &lt;snapshotRepository&gt; &lt;id&gt;ossrh&lt;/id&gt; &lt;name&gt;Sonatype Nexus Snapshots&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;repository&gt; &lt;id&gt;ossrh&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/service/local/staging/deploy/maven2/&lt;/url&gt; &lt;/repository&gt; &lt;/distributionManagement&gt; &lt;/profile&gt;&lt;/profiles&gt; 打包发布 1mvn clean deploy -P release 将上传的开源库发布出去 登录https://oss.sonatype.org/#stagingRepositories查看staging中的包 选中包，closed，解决closed的时候出现的问题，再次打包上传，直到可以closed为止 选中包，release 登录sonatype并回复issue项目已发布，等待审核]]></content>
      <categories>
        <category>maven</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
        <tag>jar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的使用（三）-- 使用gzip加速页面加载]]></title>
    <url>%2F2019%2F10%2F18%2Fusing%2Fmiddleware%2Fnginx-3%2F</url>
    <content type="text"><![CDATA[介绍Nginx实现资源压缩的原理是通过ngx_http_gzip_module模块拦截请求，并对需要做gzip的类型做gzip，ngx_http_gzip_module是Nginx默认集成的，不需要重新编译，直接开启即可。 配置说明 #$gzip_ratio计算请求的压缩率，$body_bytes_sent请求体大小 log_format main &#39;$remote_addr - $remote_user [$time_local] &quot;$host&quot; - &quot;$request&quot; &#39; &#39;$gzip_ratio - $body_bytes_sent - $request_time&#39;; access_log logs/access.log main; # 开启gzip gzip off; # 启用gzip压缩的最小文件，小于设置值的文件将不会压缩 # 当返回内容大于此值时才会使用gzip进行压缩,以K为单位,当值为0时，所有页面都进行压缩。 gzip_min_length 1k; # gzip 压缩级别，1-9，数字越大压缩的越好，也越占用CPU时间，后面会有详细说明 # 随着压缩级别的升高，压缩比有所提高，但到了级别6后，很难再提高； # 随着压缩级别的升高，处理时间明显变慢； # gzip很消耗cpu的性能，高并发情况下cpu达到100% gzip_comp_level 1; # 进行压缩的文件类型。javascript有多种形式。其中的值可以在 mime.types 文件中找到。 gzip_types text/plain application/javascript application/x-javascript text/css application/xml text/javascript application/x-httpd-php image/jpeg image/gif image/png application/vnd.ms-fontobject font/ttf font/opentype font/x-woff image/svg+xml; # 是否在http header中添加Vary: Accept-Encoding，建议开启 gzip_vary on; # 禁用IE 6 gzip # 通过表达式，表明哪些UA头不使用gzip压缩 gzip_disable &quot;MSIE [1-6]\.&quot;; # 设置压缩所需要的缓冲区大小 # 设置用于处理请求压缩的缓冲区数量和大小。比如32 4K表示按照内存页（one memory page）大小以4K为单位（即一个系统中内存页为4K），申请32倍的内存空间。建议此项不设置，使用默认值 gzip_buffers 32 4k; # 设置gzip压缩针对的HTTP协议版本 # 用于识别http协议的版本，早期的浏览器不支持gzip压缩，用户会看到乱码，所以为了支持前期版本加了此选项。默认在http/1.0的协议下不开启gzip压缩。 gzip_http_version 1.0;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据挖掘--爬虫--动态渲染页面爬取]]></title>
    <url>%2F2019%2F02%2F25%2Fmachine%20learning%2Fclawler%2Fclawler-6%2F</url>
    <content type="text"><![CDATA[selenium的使用&emsp;&emsp;官方文档&emsp;&emsp;selenium是一个自动化测试工具，利用它可以驱动浏览器执行特定的动作，还可以获取浏览器当前呈现页面的源码。 等待条件以及其含义&emsp;&emsp;官方文档 123wait = WebDriverWait(browser,1)wait.until(EC.presence_of_element_located((By.ID,'content_left')))#until中的即为等待条件 等待条件 含义 title_is 标题是某内容 title_contains 标题包含某内容 persence_of_element_localted 节点加载出来，传入定位元素，如(By.ID,’p’) visibility_of_element_localted 节点可见，传入定位元素 visibility_of 可见，传入节点对象 persence_of_all_element_localted 所有节点加载出来 text_to_be_present_in_element 某个节点文本包含某文字 text_to_be_present_in_element_value 某个节点值包含某文字 frame_to_be_availiable_and_switch_to_it 加载并切换 invisibility_of_element_located 节点不可见 element_to_be_clickable 节点可点击 staleness_of 判断一个节点是否仍在DOM，可判断页面是否已经刷新 element_t_be_selected 节点可选择，传入节点对象 element_located_to_be_clickable 节点可选择，传入定位元组 element_selection_state_to_be 传入节点对象以及状态，相等返回true，否则false element_located_selection_state_to_be 传入定位元组以及状态，相等返回true，否则false alert_is_present 是否出现警告]]></content>
      <categories>
        <category>crawler</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web crawler</tag>
        <tag>data mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据挖掘--爬虫--Ajax数据爬取]]></title>
    <url>%2F2019%2F02%2F22%2Fmachine%20learning%2Fclawler%2Fclawler-5%2F</url>
    <content type="text"><![CDATA[Ajax&emsp;&emsp;Ajax，全程Asynchronous JavaScript and XML，即异步的JavaScript和XML，在保证页面不被刷新、页面链接不改变的情况下与服务器交换数据并更新部分网页的技术。 爬取今日头条街拍123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#!/usr/bin/env python3# -*- coding: utf-8 -*-""" @author zhangbohan.dell@gmail.com@function:@create 2019/2/25 11:12"""import osfrom hashlib import md5from multiprocessing.pool import Poolimport requestsfrom bs4 import BeautifulSoupfrom urllib.parse import urlencodedef get_page(offset): params = &#123; 'aid': '24', 'app_name': 'web_search', 'offset': offset, 'format': 'json', 'keyword': '街拍', 'autoload': 'true', 'count': '20', 'en_qc': '1', 'cur_tab': '1', 'from': 'search_tab', 'pd': 'syntheis' &#125; url = 'https://www.toutiao.com/api/search/content/?' + urlencode(params) try: response = requests.get(url) if response.status_code == 200: return response.json() except requests.ConnectionError: return Nonedef get_image(json): if json.get('data'): for item in json.get('data'): title = item.get('title') images = item.get('image_list') for image in images: yield &#123; 'image': image.get('url'), 'title': title &#125;def save_image(item): if not os.path.exists(item.get('title')): os.mkdir(item.get('title')) try: response = requests.get(item.get('image')) if response.status_code == 200: file_path = '&#123;0&#125;/&#123;1&#125;.&#123;2&#125;'.format(item.get('title'), md5(response.content).hexdigest(), 'jpg') if not os.path.exists(file_path): with open(file_path, 'wb') as f: f.write(response.content) else: print('Already Downloaded', file_path) except requests.ConnectionError: print('Failed to save Image')def main(offset): json = get_page(offset) for item in get_image(json): print(item) save_image(item)GROUP_START = 1GROUP_END = 20if __name__ == '__main__': pool = Pool() groups = ([x * 20 for x in range(GROUP_START, GROUP_END + 1)]) pool.map(main, groups) pool.map(main, groups) pool.close() pool.join() 参考资料崔庆才大佬的《python3网络爬虫开发实战》]]></content>
      <categories>
        <category>crawler</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web crawler</tag>
        <tag>data mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据挖掘--爬虫--解析库]]></title>
    <url>%2F2019%2F02%2F22%2Fmachine%20learning%2Fclawler%2Fclawler-4%2F</url>
    <content type="text"><![CDATA[XPath&emsp;&emsp;XPath，全程XML Path Language，是一门在XML文档中查找信息的语言，也适用于HTML文档的搜索&emsp;&emsp;XPath用法 &emsp;&emsp; lxml库用法 概览常用规则 表达式 描述 nodename 选取此节点的所有子节点 / 从当前节点选取直接子节点 // 从当前节点选取子孙节点 . 选取当前节点 .. 选取当前节点的父节点 @ 选取属性 运算符以及介绍 运算符 描述 实例 返回值 or 或 and 与 mod 取余 \ 计算两个节点集 //book \ //cd 返回所有拥有book和cd元素的节点集 + 加法 - 减法 * 乘法 div 除法 = 等于 != 不等于 &lt; 小于 &gt; 大于 &gt;= 大于等于 &lt;= 小于等 Beautiful soup&emsp;&emsp;Beautiful Soup就是Python的一个HTML或XML的解析库 解析器Beautiful soup在解析时实际上依赖解析库，支持的解析库如下 解析器 使用的方法 优势 劣势 Python标准库 BeautifulSoup(markup,”html.parser”) Python内置标准库，执行速度适中，文档容错能力强 Python2.7.3以及3.2.2之前的版本文档容错能力差 lxml html解析器 BeautifulSoup(markup,”lxml”) 速度快，文档容错能力强 需要c语言库 lxml xml解析器 BeautifulSoup(markup,”xml”) 速度快，唯一支持xml的解析器 需要c语言库 html5lib BeautifulSoup(markup,”html5lib”) 最好的容错性、以浏览器的方式解析文档、生成html5格式的文档 速度慢、不依赖扩展 puquery&emsp;&emsp;获取元素方式和jquery类似 参考资料崔庆才大佬的《python3网络爬虫开发实战》]]></content>
      <categories>
        <category>crawler</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web crawler</tag>
        <tag>data mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据挖掘--爬虫--基础库]]></title>
    <url>%2F2019%2F02%2F22%2Fmachine%20learning%2Fclawler%2Fcrawler-3%2F</url>
    <content type="text"><![CDATA[urllib&emsp;&emsp;urllib包含4个模块： request 基本的http请求模块，用来模拟发送请求。 error 异常处理模块，用于捕获异常保证程序不会意外终止 parse 工具模块，提供了许多URL的处理方法 robotparser 主要用来识别网站中的robots.txt文件，判断哪些网页可以用来爬 requesturlopen()API—-&gt; urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None) data 添加该参数之后，请求方法即为POST；如果其内容为字节流编码格式(bytes类型)的内容，需要通过bytes()方法进行转换 123456import urllib.request as requsetimport urllib.parse as parsedata = bytes(parse.urlencode(&#123;'world':'hello'&#125;),encoding='utf-8')reponse = requset.urlopen('http://httpbin.org/post',data=data)print(reponse.read()) timeout 用于设置超时时间，单位：秒，超出这个时间没有相应，就会抛出异常,支持http、https、ftp请求 123import urllib.request as requsetreponse = requset.urlopen('http://httpbin.org/get',timeout=1) context &emsp;&emsp;用来指定ssl设置，必须是ssl.SSLContext类型 cafile和capath&emsp;&emsp;用来指定CA证书和它的路径，在https链接时会用到 cadefault&emsp;&emsp;该参数已经弃用，默认为False Request&emsp;&emsp;如果请求中需要添加header头信息，就需要使用Request类来构建请求。 API—-&gt; class urllib.request.Request(ur1, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None) url用于请求URL，必传参数 databytes（字节流）类型 headers一个字典，也就是请求头，可以通过headers参数直接构造请求头，也可以通过请求实例的add_header()方法添加 origin_req_host指的是请求方的host名称或者IP地址 unverifiable标识这个请求是够是无法验证的，默认是False，也就是用户没有权限来选择接受这个请求的结果 method指示请求使用的方法，POST、GET、PUT等 高级用法&emsp;&emsp;需要更高级的操作（Cookie处理、代理设置等）的时候，使用更加强大的工具Handler，简单的可以理解为各种处理器。BaseHandler是其他所有Handler的父类，提供了最基本的方法。 HTTPDefaultErrorHandler&emsp;&emsp;用于处理HTTP响应错误 HTTPRedirectHandler&emsp;&emsp;用于处理重定向 HTTPCookieProcesser&emsp;&emsp;用于处理Cookie ProxyHandler&emsp;&emsp;用于设置代理，默认代理为空 HTTPPasswordMgr&emsp;&emsp;用于管理密码，维护了用户名和密码的表 HTTPBasicAuthHandler&emsp;&emsp;用于管理认证 parse&emsp;&emsp;parse 模块，它定义了处理 URL 的标准接口，例如实现URL各部分的抽取、合并以及链接转换。 它支持如下协议的 URL 处理：file 、http、gopher、hdl、http、https、imap 、mailto、mms、news、nntp、prospero、rsync、rtsp、rtspu、sftp、sip、sips、snews、svn、svn+ssh、telnet和wais。 urlparse()&emsp;&emsp;可以实现URL的识别和分段，解析为6部分: scheme（协议）、netloc（域名）、path（访问路径）、params（参数）、query（查询条件）和fragment（锚点）。 API—-&gt; urllib.parse.urlparse(urlstring, scheme=”, allow_fragments=True) urlstring&emsp;&emsp;必填项，待解析的URL scheme&emsp;&emsp;默认的协议，如果链接没有带协议信息，会以此作为默认协议 allow_fragments&emsp;&emsp;是够忽略 fragement。设置为false，fragement部分就会被忽略，解析为path、parameters、或者query的一部分 urlunparse()&emsp;&emsp;接受一个可迭代的且长度为6的对象作为参数，构造一个URL 1234import urllib.parse as parsedata= ['http','www.baidu.com','index.html','user', 'a=6','comment']print(parse.urlunparse(data)) urlsplit()&emsp;&emsp;与urlparse()类似，不过不再单独解析params部分，将其合并到path中 urlunsplit()&emsp;&emsp;与urlunparse()类似，接受一个可迭代的且长度为5的对象作为参数，构造一个URL urljoin()&emsp;&emsp;提供一个base_url（基础链接）作为第一个参数，将新的链接作为第二个参数，该方法会分析base_url的scheme、netloc和path这3个内容并对新链接缺失的部分进行补充，最后返回结果。&emsp;&emsp;base_url提供了三项内容scheme、netloc和path。如果这3项在新的链接里不存在，就予以补充；如果新的链接存在，就使用新的链接的部分。而base_url中的params、query和fragment是不起作用的。 urlencode()&emsp;&emsp;通过序列化将字典转换为GET请求参数 parse_qs()&emsp;&emsp;通过反序列化将GET请求参数转换为字典 parse_qsl()&emsp;&emsp;将参数转化为元组组成的列表 quote()&emsp;&emsp;将内容转化为URL编码的格式 unquote()&emsp;&emsp;将URL编码格式的内容解码 robotparserbobots协议&emsp;&emsp;Robots协议也称作爬虫协议/机器人协议，全程网络爬虫排除协议(Robots Exclusion Protocol)，通常为一个robots.txt文本文件，存放于网站的根目录之下。 123User-agent: *Disallow: IAllow: /public/ 常见的爬虫名称 爬虫名称 名称 网站 BaiduSpider 百度 www.baidu.com Googlebot 谷歌 www.google.com 360Spider 360搜索 www.so.com YodaoBot 有道 www.youdao.com ia_archiver Alexa www.alexa.cn Scooter altavista www.altavista.com robotparser&emsp;&emsp;一些常用方法： set_url()： 用来设置robots.txt文件的链接。如果在创建RobotFileParser对象时传入了链接，那么就不需要再使用这个方法设置了 。 read()： 读取 robots.txt文件并进行分析。注意，这个方法执行一个读取和分析操作，如果不调用这个方法，接下来的判断都会为 False，所以一定记得调用这个方法。这个方法不会返回任何内容，但是执行了读取操作。 parse()： 用来解析robots.txt文件，传人的参数是robots.txt某些行的内容，它会按照 robots.txt的语法规则来分析这些内容。 can_fetch()： 该方法传人两个参数，第一个是 User-agent，第二个是要抓取的URL。返回的内容是该搜索引擎是否可以抓取这个URL，返回结果是True或False mtime()： 返回的是上次抓取和分析robots.txt的时间，这对于长时间分析和抓取的搜索爬虫是很有必要的，你可能需要定期检查来抓取最新的robots.txt。 modified() ：它同样对长时间分析和抓取的搜索爬虫很有帮助，将当前时间设置为上次抓取和分析robots.txt的时间 。 requestsGET请求1234import requestsr = requests.get('http://httpbin.org/get')print(r.text) POST请求12345import requestsdata = &#123;'name':'germey', 'age':'22'&#125;r = requests.post("http://httpbin.org/post", data=data)print(r.text) 正则表达式&emsp;&emsp;详情请看另一篇文章 爬取猫眼top10012345678910111213141516171819202122232425262728293031323334353637383940414243#!/usr/bin/env python3# -*- coding: utf-8 -*-import jsonimport refrom bs4 import BeautifulSoupimport requestsdef get_one(url): headers = &#123; 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36' &#125; response = requests.get(url) if response.status_code == 200: return response.text return Nonedef parse_one_page(html): soup = BeautifulSoup(html, features='lxml') select = soup.select('dd') for i in select: yield &#123; 'index':i.select("i.board-index").pop().text, 'name': i.select('p.name').pop().text, 'star':re.sub( "[\f\r\n\t\v ]","",i.select('p.star').pop().text), 'releasetime': i.select('p.releasetime').pop().text, 'score': i.select('p.score').pop().text&#125;def main(offset = 0): url = 'https://maoyan.com/board/4?offset='+str(offset) html = get_one(url) with open("result.txt","a+",encoding="utf-8",newline="") as f: for i in parse_one_page(html): f.write(json.dumps(i,ensure_ascii=False)+"\n")if __name__ == '__main__': for i in range(10): main(offset=i*10) 参考资料崔庆才大佬的《python3网络爬虫开发实战》]]></content>
      <categories>
        <category>crawler</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web crawler</tag>
        <tag>data mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据挖掘--爬虫--爬虫基础]]></title>
    <url>%2F2019%2F02%2F21%2Fmachine%20learning%2Fclawler%2Fcrawler-2%2F</url>
    <content type="text"><![CDATA[HTTP基本原理URI和URL&emsp;&emsp;URI(Uniform Resource Identifier),统一资源标志符；URL(Uniform Resource Locator),统一资源定位符；URN(Uniform Resource Name),统一资源名称，只命名组员而不指定如何定位资源。URL和URN都是URI的子集。 超文本hypertext&emsp;&emsp;超文本是用超链接的方法，将各种不同空间的文字信息组织在一起的网状文本。网页就是超文本的一种体现 http和httpshttp(Hyper Text Transfer Protocol)超文本传输协议。用于从网络传输超文本数据到本地浏览器接收。https(Hyper Text Transfer Protocol over Secure Socket Layer)，是以安全为目标的HTTP通道，在HTTP下加入SSL层。 http请求过程 含义 解释 Name 请求的名称 一般会将URL的最后一部分内容当做名称 Status 响应的状态码 Type 请求的文档类型 Initiator 请求源 用来标记请求是由那个对象或进程发起的 Size 从服务器下载的文件和请求的资源的大小 Time 发起请求到获取相应所用的总时间 WaterFall 网络请求的可视化瀑布流 请求&emsp;&emsp;请求可以分为4部分：请求方法(Request Method)、请求的网址(Request URL)、请求头(Request Header)、请求体(Request Body)。 请求方法&emsp;&emsp;常见请求方法有两种，GET和POST。除此之外还有PUT、DELETE、OPTIONS、CONNECT、TRACE等 方法 描述 GET 请求页面，并返回页面内容 HEAD 类似于GET，只不过返回的相应没有具体的内容，用于获取报头 POST 大多用于提交表单或者上传文件，数据包含在请求体中 PUT 从客户端向服务传送的数据取代指定文档中的内容 DELETE 请求服务器删除指定的页面 CONNECT 把服务器当做跳板，让服务器代替客户端访问其他页面 OPTIONS 允许客户端查看服务器的性能 TRACE 回显服务器收到得的请求，主要用于测试或者诊断 请求的地址&emsp;&emsp;即URL，可以确定请求的资源 请求头&emsp;&emsp;用来说明服务器要是使用的附加信息 请求头信息 说明 Accept 请求报头域，用于指定客户端可以接受那些类型的信息 Accept-Language 指定客户端可以接受的语言类型 Accept-Encoding 指定客户端可以接受的内容编码 Host 用于指定请求资源的主机IP和端口号，其内容为请求地址的原始服务器或者网关位置 Cookie(s) 网站为了辨别用户进行会话跟踪而存储在用户本地的数据 Referer 用来标识这个请求是从哪个页面发送过来的 User-Agent（UA） 可以使服务器是被客户使用的操作系统以及版本、浏览器以及版本信息 Content-Type 互联网媒体类型/MIME类型，用来表示具体请求中的媒体类型信息 请求体 &emsp;&emsp;一般承载的内容是POSt请求中的表单数据，而对于GET请求，请求体为空 响应&emsp;&emsp;由服务器返回给客户端，可以分为三部分:响应状态码(Response Status Code)、响应头(Response Header)、响应体(Response Body) 响应的状态码&emsp;&emsp;表示服务器的响应状态。 状态码 说明 详情 100 继续 请求者应当继续提出请求，服务器已经接受部分请求，正在等待其余部分 101 切换协议 请求者已要求服务器切换协议，服务器已确认并做好准备 200 成功 服务器已经处理好了请求 201 已创建 请求成功并且服务器创建了新的资源 202 已接受 服务器已经接受请求，但是尚未处理 203 非授权信息 服务器已成功处理了请求，但返回的信息可能来自另一个源 204 无内容 服务器已经处理了请求，但没有认可返回信息 205 重置内容 服务器成功处理了请求，内容被重置 206 部分内容 服务器成功处理了部分请求 300 多种选择 针对请求，服务器可执行多种选择 301 永久移动 请求的网页已经永久移动到新位置，即永久重定向 302 临时移动 请求的网页暂时跳转到其他页面，即临时重定向 303 查看其他位置 如果原来的请求是POST，重定向目标文档应该通过GET获取 304 未修改 此次请求返回的网页未修改，继续使用上次的资源 305 使用代理 请求者应该使用代理访问该页面 307 临时重定向 请求的资源临时从其他位置响应 400 错误请求 服务器无法解析该请求 401 未授权 请求没有进行身份验证或者验证未通过 403 禁止访问 服务器拒绝该请求 404 未找到 服务器找不到请求的页面 405 方法禁用 服务器禁用了请求中指定的方法 406 不接受 无法使用请求的内容相应请求的网页 407 需要代理授权 请求者需要代理授权 408 请求超时 服务器请求超时 409 冲突 服务器在完成请求时发生冲突 410 已删除 请求的资源已永久删除 411 需要有效长度 服务器不接受不含有有效长度标头字段的请求 412 为满足前提条件 服务器为满足请求者在请求中设置的一个前提条件 413 请求实体过大 请求实体过大，超出服务器处理范围 414 请求URI过长 请求网址过长，服务器无法处理 415 不支持类型 请求个事不被请求页面支持 416 请求范围不符 页面无法提供请求的范围 417 未满足期望值 服务器未满足期望请求标头字段的要求 500 服务器内部错误 服务器遇到错误，无法完成请求 501 未实现 服务器不具备完成请求的功能 502 错误网关 服务器作为网关或者代理，从上游服务器收到无效响应 503 服务不可用 服务器目前无法使用 504 网关超时 服务器作为网关或者代理，但是没有及时从上游服务器收到请求 505 HTTP版本不支持 服务器不支持请求中所用的HTTP协议版本 响应头&emsp;&emsp;响应头包含了服务器对请求的应答信息，常见的应答信息： 标签 含义 Date 标识响应产生的时间 Last-Modified 指定资源的最后修改时间 Content-Encoding 指定响应内容的编码 Server 包含服务器的信息（名称、版本号等） Content-Type 文档类型 Set-Cookie 设置Cookie Expires 指定响应的过期时间，可以使用代理服务器或者浏览器将加载的内容更新到缓存中 响应体&emsp;&emsp; 相应的正文 爬虫原理概述&emsp;&emsp;爬虫就是获取网页并提取保存信息的自动化程序。 参考资料崔庆才大佬的《python3网络爬虫开发实战》]]></content>
      <categories>
        <category>crawler</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web crawler</tag>
        <tag>data mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据挖掘--爬虫--准备工作]]></title>
    <url>%2F2019%2F02%2F21%2Fmachine%20learning%2Fclawler%2Fcrawler-1%2F</url>
    <content type="text"><![CDATA[python环境的准备工作&emsp;&emsp;博主在这使用windows作为系统环境，安装anaconda3作为python运行与库管理环境。&emsp;&emsp;anaconda官方网站&emsp;&emsp;如果下载速度过慢，可以选择使用清华大学镜像，使用说明 请求库的安装requests库&amp;emsp;&amp;emsp;阻塞式http请求库 1pip3 install requests selenuim库 &emsp;&emsp;selenuim是一个自动化测试工具，可以使用它驱动浏览器执行特定的动作。如点击，下拉等等 1pip3 install selenuim Google Chrome 以及其驱动 ChromeDriver&amp;emsp;&amp;emsp;Google Chrome[下载](https://chrome.en.softonic.com/)&amp;emsp;&amp;emsp; ChromeDriver[下载](https://chromedriver.storage.googleapis.com/index.html) &lt;font color=&quot;red&quot;&gt;注意：安装的chromedriver版本要和google chrome版本相匹配&lt;/font&gt; &amp;emsp;&amp;emsp;将下载下来的chromedriver添加到环境变量，在命令行中进行测试是否成功 1chromedriver 显示以下类似内容说明成功 123Starting ChromeDriver 72.0.3626.69 (3c16f8a135abc0d4da2dff33804db79b849a7c38) on port 9515Only local connections are allowed.Please protect ports used by ChromeDriver and related test frameworks to prevent access by malicious code 在python中进行测试 12from selenium import webdriver brower = webdriver.Chrome() 运行打开一个新的chrome窗口 Firefox以及其驱动 GeckoDriverFireFox[下载](http://www.firefox.com.cn/)&amp;emsp;&amp;emsp;GeckoDriver[下载](https://github.com/mozilla/geckodriver/releases) &lt;font color=&quot;red&quot;&gt;注意：安装的geckodriver版本要和firefox版本相匹配,geckodriver下载界面有版本要求说明，如果geckodriver未起作用，请尝试重装firefox最新版本并重启电脑&lt;/font&gt; &amp;emsp;&amp;emsp;将下载下来的geckodriver添加到环境变量，在命令行中进行测试是否成功 1geckodriver 在python中进行测试 12from selenium import webdriverbrower = webdriver.Firefox() 运行打开一个新的firefox窗口 PhantomJS &emsp;&emsp;PhantomJS是一个无界面的、可脚本编程的webkit浏览器引擎，下载 &emsp;&emsp;将下载下来的bin文件夹下的phantomjs.exe添加到环境变量，在命令行中进行测试是否成功 1phantomjs 出现以下内容说明可用 1phantomjs&gt; 在python中进行测试 12345from selenium import webdriverbrower = webdriver.PhantomJS()brower.get("http://www.baidu.com")print(brower.current_url)) 使用PhantonJs不会打开一个新的窗口，但实际上已经在后台运行 aiohttp异步web服务库 1pip3 install aiohttp 此外，官方还推荐安装cchardet（字符编码检测库）和aiodns（加速dns解析库）， 1pip3 install cchardet aiodns 解析库的安装lxml 支持html和xml的解析，支持XPath解析方式，解析效率高 1pip3 install lxml Beautiful Soup1pip3 install beautifulsoup4 pyquery&emsp;&emsp;pyquery 同样是一个强大的网页解析工具，它提供了和 jQuery 类似的语法来解析 HTML 文梢，支持 css 选择器，使用非常方便. 1pip3 install pyquery tesserocr &emsp;&emsp;cor识别，识别各种各样的验证码。tesserocr是对tesseract的一层python封装，因此需要先安装tesseract,带dev的是开发版本，不稳定，不带dev的是稳定版本 linux下 1pip3 install tesserocr pillow windows下 whl安装文件下载地址 1pip install tesserocr-2.4.0-cp36-cp36m-win_amd64.whl 保存测试图片到本地，分别对tesseract和tesserocr进行测试，看能否识别 1234tesseract image.png result -l eng &amp;&amp; type result.txt#运行结果#Tesseract Open Source OCR Engine v3.0S .01 with Leptonica#Python3WebSpider 1234import tesserocrfrom PIL import Imageimage = Image.open('D:\\temp\\test\\image.png')print(tesserocr.image_to_text(image)) 数据库(略)存储库PyMysql1pip3 install pymysql PyMongo1pip3 install pymongo redis-py1pip3 install redis WEB库flask1pip3 install flask Tornado&emsp;&emsp;Tornado是一个支持异步的web框架，通过使用非阻塞I/O流，可以支撑成千上万的开放连接，效率非常高。 1pip3 install tornado App爬取相关库(暂时放弃)爬虫框架pyspider&emsp;&emsp;它带有强大的WebUI、脚本编辑器、任务监控器、项目管理器以及结果处理器，同时支持多种数据库后端、多种消息队列，另外还支持JavaScript渲染页面的爬取&emsp;&emsp;pyspider是支持JavaScript渲染的，而这个过程是依赖于PhantomJS的，所以还需要安装PhantomJS 1pip3 install pyspider Scrapy1pip3 install scrapy 参考资料崔庆才大佬的《python3网络爬虫开发实战》]]></content>
      <categories>
        <category>crawler</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>web crawler</tag>
        <tag>data mining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[向量]]></title>
    <url>%2F2018%2F12%2F28%2Ftheory%2Falgorithm%2Fdsa%2Fvector%2F</url>
    <content type="text"><![CDATA[向量ADT(Aabstract data type)&emsp;&emsp;抽象数据类型，数据模型+定义在该模型上的一组操作 DS(Data Structure)&emsp;&emsp;数据结构, 基于某种特定语言，实现ADT的一整套算法 &emsp;&emsp;c/c++语言中，数组A[]中的元素与[0,n)内的编号一一对应。每个元素均可以有编号唯一指代，并可以直接访问，也称之为线性数组。&emsp;&emsp;向量是数组的抽象与泛化，由一组元素按线性次序封装而成. 各元素与[0,n)内的秩一一对应 (循秩访问) 元素的类型不局限于基本类型 操作、管理更加简化、统一与安全 可更为便捷的参与复杂的数据类型的定制与实 现 向量ADT接口 操作 功能 适用对象 size() 报告向量当前的规模(向量长度) 向量 Get(r) 获取秩为r的元素 向量 put(r,e) 用e替换秩为r元素的数值 向量 insert(r,e) e作为秩为r元素插入，原后继元素依次后移 向量 Remove(r) 删除秩为r的元素，返回该元素中原本存放的对象 向量 disordered() 判断所有元素是否已按非降序排列 向量 sort() 调整各元素位置，使之按非降序排列 向量 find(e) 查找目标元素e 向量 search(e) 查找目标元素e，返回不大于e且秩最大的元素 有序向量 deduplicate() 剔除重复元素 向量 Uniquify 剔除重复元素 有序向量 traverse() 遍历向量并统一处理所有元素，处理方法由函数对象制定 向量 递增式扩容最坏情况：在初始容量为0的空向量中，连续插入n=m*I &gt;&gt; 2个元素…在1，I+1,2I+1..都需要扩容 总体耗时：I*(m-1)*m/2 = O(n^2) \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; 平均分摊成本 O(n)装填因子：100% 加倍式扩容最坏情况： 在初始容量为1的空向量中，连续插入$n=2^m &gt;&gt; 2$个元素在1,2,4,8…都需要扩容 总体耗时：O(n) \;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\; 平均分摊成本 O(1)装填因子：50%]]></content>
      <categories>
        <category>dsa</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>dsa</tag>
        <tag>adt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ElasticSearch学习笔记（一）]]></title>
    <url>%2F2018%2F12%2F04%2Fusing%2Fmiddleware%2Felk-1%2F</url>
    <content type="text"><![CDATA[ElasticSearch(ES)有关的基本概念 Cluster和Node&emsp;&emsp;ES中的Cluster是对外提供搜索服务的集群，组成这个Cluster的各个节点叫做Node。&emsp;&emsp;Node分类：IndexNode（提供读写），DataNode（只提供数据存储和访问，负载均衡等），节点之间关系对等，弱化的Master节点提供维护集群状态的功能 Shards&emsp;&emsp;ES将一个完整的索引分成若干部分，每一个部分就是一个Shards，每一个Shards实际上是一个基于Lucene的索引，Shards数量一遍在创建索引前指定，且索引创建后不能修改，es的检索实际上是对多个Shards上的搜索结果的合并 Replicas&emsp;&emsp;Replicas是索引的冗余备份，可用于放置数据丢失或用来做负载均衡 Recovery&emsp;&emsp;在有节点加入或者退出集群的时候，ES会对索引分片Shards重新分配 River&emsp;&emsp;River是一个运行在集群内部的插件，用来从外部获取异构数据，然后在ES里创建索引。常见的有RabbitMQ river Plugin、MongoDB river Plugin等 Gateway&emsp;&emsp;是ES索引数据快照的存储方式，当ES关机重启的时候，就会从Gateway中读取索引快照 Discovery.zen&emsp;&emsp;Es的自动发现节点机制，用来实现节点自动发现和Master节点选举，Master节点负责处理及节点的加入和退出以及分片Shards的重新分配 Transport&emsp;&emsp;代表ES内部节点或者集群与客户端的交互方式。默认TCP，同时支持HTTP（JSON）、Thrift、Servlet等 Index、Type、Document、Field &emsp;&emsp;Index是ES存储数据的地方，类似RDBMS的Database;Type类似于table;Document是一行数据，可以有不同字段集合;Field是最小存储单位 Mapping&emsp;&emsp;定义索引下Type的字段处理规则 ES默认端口9200 是HTTP端口，9300 是Transport端口 ES索引机器构建&emsp;&emsp;ES是基于Luence构建的，采用倒排索引机制，将文件封装为索引，将文本信息切分为成为Token的信息单元，再利用这些Token构建倒排索引。]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>elk</tag>
        <tag>midedleware</tag>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK日志分析系统搭建过程以及使用说明]]></title>
    <url>%2F2018%2F12%2F04%2Fusing%2Fmiddleware%2Felk%2F</url>
    <content type="text"><![CDATA[环境搭建环境搭建说明Centos 7 *2 + elastics 5.6.12 + logstash 5.6.12 + kibana 5.6.12 + filebeat 5.6.12 ElasticSearch环境搭建 下载解压 12wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.12.tar.gztar -zxvf elasticsearch-5.6.12.tar.gz -C /elk/elasticsearch/ 配置/config/elasticsearch.yml 1234network.host: 0.0.0.0 # 访问地址http.port: 9200 #端口号cluster.name: nmtx-clusternode.name: node-1 运行 12nohup ./bin/elasticsearch &gt; ../logs/elasticsearch.log 2&gt;&amp;1 &amp; echo $! &gt; process.pid#在后台运行，日志打印到../logs/elasticsearch.log，进程号保存至process.pid 踩过的坑 不要使用root账户启动elasticsearch，这是出于系统安全考虑设置的条件。 max virtual memory areas vm.max_map_count [65530] is too low, increase to at ，需要调整虚拟内存设置 123456vim /etc/sysctl.conf#添加如下信息并保存vm.max_map_count=655360#运行以生效sysctl -p 需要修改linux对文件、线程的限制 12345#修改系统文件vim /etc/security/limits.d/20-nproc.conf#调整成以下配置* soft nproc 4096root soft nproc unlimited 验证 &emsp;&emsp;访问9200端口看到如下类似信息即可 12345678910111213&#123;"name" : "node-1","cluster_name" : "nmtx-cluster","cluster_uuid" : "plk3ql1SQ2umnqSpyBGI_w","version" : &#123; "number" : "5.6.12", "build_hash" : "cfe3d9f", "build_date" : "2018-09-10T20:12:43.732Z", "build_snapshot" : false, "lucene_version" : "6.6.1"&#125;,"tagline" : "You Know, for Search"&#125; filebeat环境搭建什么是Beats&emsp;&emsp;Beats 是安装在服务器上的数据中转代理，Beats 可以将数据直接传输到 Elasticsearch 或传输到 Logstash 。常见的Beats： Packetbeat：网络数据包分析器，提供有关您的应用程序服务器之间交换的事务的信息。 Filebeat：从您的服务器发送日志文件。 Metricbeat：是一个服务器监视代理程序，它定期从服务器上运行的操作系统和服务收集指标。 Winlogbeat：提供Windows事件日志。 为什么使用filebeat&emsp;&emsp;相比 Logstash，FileBeat 更加轻量化。在任何环境下，应用程序都有停机的可能性。 Filebeat 读取并转发日志行，如果中断，则会记住所有事件恢复联机状态时所在位置 。Filebeat带有内部模块（auditd，Apache，Nginx，System和MySQL），可通过一个指定命令来简化通用日志格式的收集，解析和可视化。FileBeat 不会让你的管道超负荷。FileBeat 如果是向 Logstash 传输数据，当 Logstash 忙于处理数据，会通知 FileBeat 放慢读取速度。一旦拥塞得到解决，FileBeat 将恢复到原来的速度并继续传播。 下载与安装 12wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.6.12-linux-x86_64.tar.gztar -zxvf ilebeat-5.6.12-linux-x86_64.tar.gz -C /elk/filebeat/ 配置filebeat.yml 123456789101112131415161718192021222324252627filebeat.prospectors:# Each - is a prospector. Most options can be set at the prospector level, so# you can use different prospectors for various configurations.# Below are the prospector specific configurations.- input_type: log# Paths that should be crawled and fetched. Glob based paths.paths: - /var/log/*-info.log #监听文件目录以及正则匹配规则 #- c:\programdata\elasticsearch\logs\* windows下的路径multiline: # 日志多行处理，列如java的堆栈信息 pattern: ^\d&#123;4&#125; # 匹配前缀为数字开头，如果不是日期，该行日志接到上一行后尾 negate: true match: afterfields: # 自定义属性，用于 Logstash 中 service_name: customer # 产生日志的服务名 log_type: info # 日志文件类型 server_id: ip-address # 服务器ip地址#----------------------------- Logstash output --------------------------------output.logstash:# The Logstash hostshosts: ["localhost:5043"] #这里是发送到本地的logstash，要与logstash的input对应，也可以设置为elasticsearch 运行 1nohup ./filebeat -e -c filebeat.yml &gt; ../logs/filebeat.log 2&gt;&amp;1 &amp; echo $! &gt; process.pid logstash环境搭建 下载与安装 12wget https://artifacts.elastic.co/downloads/logstash/logstash-5.6.12.tar.gztar -zxvf logstash-5.6.12.tar.gz -C /elk/logstash/ 配置logstash /config/logstash.conf 123456789101112131415161718192021222324252627282930313233343536373839input &#123; beats &#123; host =&gt; "localhost" #监听本地访问的5043端口 port =&gt; "5043" &#125; beats&#123; host =&gt; "0.0.0.0" #监听任何地址都可访问的5044端口 port =&gt; "5044" &#125;&#125;filter &#123; if [fields][log_type] == 'error' &#123; grok &#123; match =&gt; &#123; "message" =&gt; "%&#123;TIMESTAMP_ISO8601:logdate&#125; %&#123;LOGLEVEL:loglevel&#125; %&#123;JAVACLASS:class&#125; %&#123;NUMBER:thread&#125; %&#123;JAVALOGMESSAGE:logmsg&#125;" &#125; &#125; date &#123; # 将 kibana 的查询时间改成日志的打印时间，方便之后查询，如果不改的话，kibana会有自己的时间，导致查询不方便 match =&gt; ["logdate", "yyyy-MM-dd HH:mm:ss Z", "ISO8601"] target =&gt; "@timestamp" &#125; &#125; if [fields][log_type] == 'info' &#123; # 如果是info类型该怎么格式，这里是重复的，如果有日志格式不一样比如nginx的日志类型，可以在这里自己定义 grok &#123; match =&gt; &#123; "message" =&gt; "%&#123;TIMESTAMP_ISO8601:logdate&#125; %&#123;LOGLEVEL:loglevel&#125; %&#123;JAVACLASS:class&#125; %&#123;NUMBER:thread&#125; %&#123;JAVALOGMESSAGE:logmsg&#125;" &#125; &#125; date &#123; match =&gt; ["logdate", "yyyy-MM-dd HH:mm:ss Z", "ISO8601"] target =&gt; "@timestamp" &#125; &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; ["localhost:9200"] index =&gt; "%&#123;[fields][service_name]&#125;-%&#123;+YYYY.MM.dd&#125;" # 在es中存储的索引格式，按照“服务名-日期”进行索引 &#125;&#125; 运行 1nohup bin/logstash -f config/logstash.conf &gt; ../logs/logstash.log 2&gt;&amp;1 &amp; echo $! &gt; process.pid kibana环境搭建 下载与安装 12wget https://artifacts.elastic.co/downloads/kibana/kibana-5.6.12-linux-x86_64.tar.gztar -zxvf kibana-5.6.12-linux-x86_64.tar.gz -C /elk/kibana/ 配置kibana /config/kibana.log 123server.port: 5601server.host: "0.0.0.0" #允许其他终端访问elasticsearch.url: "http://localhost:9200" #elasticsearch访问地址 运行 1nohup bin/kibana &gt; ../logs/kibana.log 2&gt;&amp;1 &amp; echo $! &gt; process.pid 验证&emsp;&emsp;访问5601端口有页面即为正常 使用说明Kibana使用说明 查看系统运行状态&emsp;&emsp;访问http://localhsot:5601/status 基本使用&emsp;&emsp;在 Discover 页搜索和浏览数据；在 Visualize 页做数据图表映射；在 Dashboard 页创建并查看自定义仪表板。 参考资料：https://www.elastic.co/guide/cn/kibana/current/index.html elasticsearch查询语法 其中status字段包含active &emsp;&emsp;-&gt;&emsp;&emsp; status:active 其中title字段包含quick或brown。如果省略OR运算符，将使用默认运算符 &emsp;&emsp; -&gt; &emsp;&emsp; title:(quick OR brown) 或者是title:(quick brown) 其中author字段包含精确短语”john smith” &emsp;&emsp; -&gt; &emsp;&emsp; author:”john smith” 其中任何字段book.title，book.content或book.date包含 quick或brown（注意我们需要如何*使用反斜杠转义） &emsp;&emsp; -&gt; &emsp;&emsp; 该字段title具有任何非null值：&emsp;&emsp;-&gt;&emsp;&emsp;_exists_:title 通配符搜索可以在单个术语上运行，使用?替换单个字符，并*替换零个或多个字符 请注意，通配符查询可能会占用大量内存并执行得非常糟糕 - 只需考虑需要查询多少个术语以匹配查询字符串"a* b* c*"。 正则表达式 &emsp;&emsp;-&gt;&emsp;&emsp; /pattern/ 模糊 &emsp;&emsp;-&gt;&emsp;&emsp; quikc~brwn~foks~ 邻近搜索 邻近搜索允许我们指定短语中单词的最大编辑距离：&emsp;&emsp;-&gt;&emsp;&emsp;”fox quick”~5 范围 可以为日期，数字或字符串字段指定范围。包含范围用方括号指定，[min TO max]排他范围用大括号指定{min TO max}。 保留字符 + - = &amp;&amp; || &gt; &lt; ! ( ) { } [ ] ^ “ ~ * ? : \ / 分组 可以将多个术语或子句与括号组合在一起，以形成子查询： 布尔运算符 首选运算符+（此术语必须存在）和- （此术语不得出现）。 提升 使用boost运算符^使一个术语比另一个术语更相关。例如，如果我们想要找到关于fox的所有文件，但我们对quick fox特别感兴趣 &emsp;&emsp;-&gt;&emsp;&emsp; quick^2 fox 参考资料 https://www.elastic.co/guide/en/elasticsearch/reference/6.0/query-dsl-query-string-query.html#_boosting]]></content>
      <categories>
        <category>elk</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>elk</tag>
        <tag>midedleware</tag>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shiro框架基础知识]]></title>
    <url>%2F2018%2F11%2F24%2Fusing%2Fjava%2Fframework%2Fshiro%2F</url>
    <content type="text"><![CDATA[简介&emsp;&emsp;Shiro是java的一个安全框架。可以帮助我们完成：认证、授权、加密、会话管理、与web集成、缓存等功能。&emsp;&emsp;Shiro不会去维护用户、维护权限，需要我们自己去提供设计，然后通过相应接口注入给shiro。 身份验证&emsp;&emsp;在shiro中，用户需要提供principals(身份)credentials(证明)，从而验证用户身份。 principals： 身份，及主体的标识属性，唯一即可。一个主题可以有多个principals，但是只能拥有一个primary principal。 credentials： 证明/凭证，只有主体知道的安全值。如密码/数字证书等 授权主体&emsp;&emsp;即访问应用的用户，在shiro中使用Subject代表该用户，用户只有在授权后才允许访问相应的资源。 资源&emsp;&emsp;在应用中用户可以访问的任何东西，比如：页面，查看/编辑数据,访问某个业务方法、打印文本等。用户只有授权后才能访问。 权限&emsp;&emsp;安全策略中的原子授权单位，权限代表在用户中能不能访问某个资源。Shiro支持粗颗粒权限（如用户模块的所有权限）和细颗粒权限（操作某个用户的权限）。 角色&emsp;&emsp;角色代表了操作集合，可以理解为权限的集合，一般情况下，我们会赋予用户角色而不是权限。 隐式角色&emsp;&emsp;直接通过角色来验证用户有没有操作权限。粒度是以角色为单位进行访问控制的，粒度较粗；如果进行修改可能造成多处代码修改。 显示角色&emsp;&emsp;在程序中通过权限控制水能访问某个资源，角色聚合一组权限集合。粒度是以资源/实例为单位的，粒度较细。 Permission字符通配符权限&emsp;&emsp;规则：“资源通配符:操作:对象实例id” ，即对那个资源可以进行什么操作。“:”代表资源/操作/实例的分割；“,”表示操作的分割；“*”表示任意资源/操作/实例。 性能问题&emsp;&emsp;可以考虑配合缓存来提供其性能，如果这样性能还打不到要求，我们可以实现位操作算法实现性能更好的权限匹配。也可以考虑在sql查询的时候加上权限字符串以在查询时就完成权限匹配。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>shiro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大数据环境搭建过程记录]]></title>
    <url>%2F2018%2F11%2F23%2Fusing%2Fbigdata%2Fbigdata-server-environment-construct%2F</url>
    <content type="text"><![CDATA[步骤一、配置免密登录&emsp;&emsp;配置服务器间ssh免密登录https://atbulbs.github.io/2018/02/03/Hexo%E5%8D%9A%E5%AE%A2%E7%9A%84%E4%BD%BF%E7%94%A8/ 前提条件 系统已经安装有ssh 操作用户最好拥有/etc/hosts文件的读写权限或者用户拥有sudo权限 操作用户拥有ssh-keygen命令权限 过程 修改hostss文件(/etc/hosts) 1sudo vim /etc/hosts 添加以下内容 123192.168.126.150 hadoop1192.168.126.151 hadoop2192.168.126.152 hadoop3 在每一台服务器上生成ssh登录密钥 1ssh-keygen -t rsa &emsp;&emsp;在~文件夹（当前用户个人目录）下生成.ssh隐藏文件夹以及id_rsa id_rsa.pub文件，id_rsa是私钥文件，id_rsa.pub是公钥文件 分别将所有的（这里指三台服务器）id_rsa.pub内的内容拼接到一个文件中(authorized_keys),内容如下 123ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA9/09V+rJxmK1Qpoh3q1egXc1XLaBhO/gZCvQYzdC3CqN3Bv+IYduernvSXCLGZGweDP3Caw223/QiDDe2g2FB3+XmUSlkldpaRS5fGMIO4OAM5MjNtmkiruLuH0d8OQubxkzT8TTCfJLosfnT0jbls6cYPHmidcy1jAU82TpExCgz73zrJNLRXnS7tPPMW4IK9A0mChg11Ohn+ldZOqK7P80kR5951rHBd97fCLl8xl5UZ1Ep5XslT+Q+DLUhYPXk0NWNnDCPNsnNEAdF/jfBOOscrZkU0ahz1rYP6Zz9xDcC2kxhEDwf9aXD/wLOXJv4B/hv6/RUtrbYVrl3Fk30w== test@hadoop01ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA4Sd0LKEhnuHhYdI/nM8diQZSKjeJ4LYIjyVqqdp1igKXFBxU2EcVADkq4S/Uupx5GBlTxmVWWREp5W3pcK0Z+I8FCpr4AAVpKqOOua5RUJg7NzmTiWf9tUnVKerwa7IYi/n0wuwBNyps123ajOtNkC4oFez3NQgXywpMX7wIQVLCldtRQCm2UHZQHMU55qHnEj3BzZqNg4vdPRygxDZubB65pQJVIBWp03LsKUahm3bL3hUL7A2mlUwCz/mXZrZUc1q/DSmGIGpxc2jc/ukSV/gG5APgyxTiEkvSIECPWhP9fJCGlTbng+NXVFtbPQ6vI0Mblb02s4G8tMWvRB9Jrw== test@hadoop02ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA3GLFdnz5aOG3XLT+8GR/YzqJXG2K+b7M+CRiVRPcqJJvqe9UFu8/IydM/jQTIi5OhHBXqnGMcAjK76fEkMiWaPdmILbiMYr11Lx56ZhqRqsVvE8ndO2f5j45vvADZbGAJWGEVIr6tnf6QBocBg/j4h9BWryFvgfhdzM+C3CZmyRyOUJwz8NNmkXySIH/1EUHOSrwmOnO12HwLW3/nXaowR9KfyYbz2tjNJdGApeQwVQgkKeFZ8Pqq8UZBcFZeg3Zbzdwxo86y1lUxL896Wgh++jhys5eyKgruOgnSgbqy0kOu32R/uRaSt9IrnkPMPGaEi340x9+mcm9c8/PoU36Cw== test@hadoop03 将authorized_keys文件上传到每一台服务器下的~/.ssh/下 修改.ssh文件夹以及authorized_keys文件的权限 12chmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys 验证&emsp;&emsp;使用ssh命令登录其他两台服务器，成功即可，如果服务器间的用户名相同，则可以忽略用户名 步骤二、jdk安装与配置&emsp;&emsp;下载安装jdk并配置环境变量 前提条件 已经下载jdk的安装包（这里选用tar.gz压缩包文件） 操作用户最好拥有/etc/profile文件的读写权限或者用户拥有sudo权限 安装配置过程 解压 12mkdir -p /opt/javatar -zxvf jdk-8u201-linux-x64.tar.gz -C /opt/java 修改环境变量 1sudo vim /etc/profile 在profile文件末尾添加 123export JAVA_HOME=/opt/java/jdk1.8.0_201export PATH=$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/binexport CLASSPATH=.$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 使修改的profile立刻生效 1source /etc/profile 步骤三、zookeeper安装与配置&emsp;&emsp;配置zookeeper集群 前提条件 已经下载zookeeper的安装包 安装配置过程 解压安装包 12mkdir -p /opt/zookeepertar -zxvf zookeeper.tar.gz -C /opt/zookeeper 配置zoo.cfg 在zookeeper/conf目录下，将zoo_sample.cfg复制为zoo.cfg，在其中配置 1234567tickTime=4000initLimit=20dataDir=/opt/zookeeper/dataclientPort=2181server.1=192.168.126.150:2888:3888server.2=192.168.126.151:2888:3888server.3=192.168.126.152:2888:3888 注意，zookeeper集群中所有节点的zoo.cfg文件一致。 在zoo.cfg配置的dataDir下创建myid文件，其中只有一个数字，表明当前节点的server.id，与zoo.cfg中配置一致。 修改日志文件输出位置(红色为需要修改的地方)，按天输出到指定文件夹 12mkdir -p /opt/log/zookeepervim /opt/zookeeper/bin/zkEnv.sh 12345678if [ "x$&#123;ZOO_LOG_DIR&#125;" = "x" ]thenZOO_LOG_DIR="/opt/log/zookeeper/"fiif [ "x$&#123;ZOO_LOG4J_PROP&#125;" = "x" ]thenZOO_LOG4J_PROP="INFO,ROLLINGFILE"fi 1vim /opt/zookeeper/conf/log4j.properties 12zookeeper.root.logger=INFO, ROLLINGFILElog4j.appender.ROLLINGFILE=org.apache.log4j.DailyRollingFileAppender 启动zk服务：zkServer.sh start（启动应尽量所有节点同时启动） 停止zk服务：zkServer.sh stop 查看zk状态：zkServer.sh status 重启zk服务：zkServer.sh restart 步骤四、hadoop安装与配置 安装和配置hadoop1节点的hadoop 配置hadoop-env.sh 配置jdk安装目录 配置hadoop配置文件目录 配置环境变量 12export JAVA_HOME=/opt/java/jdk1.8.0_201export HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop 配置core-site.xml 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://ns&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/log/hadoop&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;hadoop1:2181,hadoop2:2181,hadoop3:2181&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置hdfs-site.xml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;ns&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.ns&lt;/name&gt; &lt;value&gt;nn1,nn2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns.nn1&lt;/name&gt; &lt;value&gt;hadoop1:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns.nn1&lt;/name&gt; &lt;value&gt;hadoop1:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.ns.nn2&lt;/name&gt; &lt;value&gt;hadoop3:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.ns.nn2&lt;/name&gt; &lt;value&gt;hadoop3:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://hadoop1:8485;hadoop2:8485;hadoop3:8485/ns&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/journal&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.ns&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfence&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/home/sysmon/.ssh/id_rsa&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/opt/log/hadoop/namenode&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/opt/log/hadoop/datanode&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置mapred-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置yarn-site.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties --&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt; &lt;value&gt;rm1,rm2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt; &lt;value&gt;hadoop1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt; &lt;value&gt;hadoop2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt; &lt;value&gt;hadoop1:2181,hadoop2:2181,hadoop3:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt; &lt;value&gt;yarn-ha&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt; &lt;value&gt;4&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;4096&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置环境变量 12345export JAVA_HOME=/opt/java/jdk1.8.0_201export ZOO_HOME=/opt/zookeeperexport HADOOP_HOME=/opt/hadoopexport PATH=$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$ZOO_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbinexport CLASSPATH=.$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 根据配置文件，创建相关文件夹，用来存放对应数据 在hadoop目录下创建 journal目录 在/opt/log/hadoop/目录下 创建namenode，datanode目录 通过scp命令，将hadoop安装目录远程cp到其他节点 启动zookeeper集群 1zkServer.sh start 格式化zookeeper在有namenode的节点上 执行 1hdfs zkfc -formatZK #这个指令的作用是在zookeeper集群上生成ha节点 启动journalnode集群在三个节点上分别执行 1hadoop-daemon.sh start journalnode 在hadoop1节点上格式化namenode 1hadoop namenode -format 启动hadoop1节点的namenode 1hadoop-daemon.sh start namenode 把hadoop3节点变为 standby namenode节点在hadoop3节点上执行 12hdfs namenode -bootstrapStandbyhadoop-daemod.sh start namenode 在三个节点上启动datanode节点，分别执行 1hadoop-daemon.sh start datanode 启动zkfc（启动FalioverControllerActive）在hadoop1，hadoop3节点上执行 1hadoop-daemon.sh start zkfc 在hadoop1节点上启动resourcemanager 1start-yarn.sh 在hadoop2节点上启动副resourcemanager 1yarn-daemon.sh start resourcemanager 启动之后hadoop1节点的进程状态： 12345678915376 ResourceManager20610 Jps20468 Kafka18838 QuorumPeerMain14999 DataNode14809 NameNode15484 NodeManager14590 JournalNode15182 DFSZKFailoverController hadoop2节点的进程状态： 12345623554 DataNode23842 ResourceManager24068 NodeManager24965 Jps25690 QuorumPeerMain23324 JournalNode hadoop3节点进程状态： 1234567822340 Jps16391 JournalNode16872 DataNode17081 DFSZKFailoverController22092 Kafka25932 QuorumPeerMain17437 NodeManager16719 NameNode 步骤五、kafka安装 解压软件 12mkdir -p /opt/kafkatar -zxvf kafka_2.11-1.0.2\ .tgz -C /opt/kafka 修改配置文件 config/server.properties —-红色为修改内容，黑色为原先内容，蓝色为添加内容 broker.id=0 #集群内kafka的id，每一台都不能一样 host.name=192.168.126.150 log.retention.hours=168 message.max.byte=5242880 default.replication.factor=2 replica.fetch.max.bytes=5242880 启动（每一台集群内的服务器） 12cd /opt/kafka/kafka_2.11-1.0.2/bin./kafka-server-start.sh -daemon ../config/server.properties 测试 12345#一台服务器中创建消息队列test1，指定2个副本，1个分区./kafka-topics.sh --create --zookeeper hadoop1:2181,hadoop2:2181,hadoop3:2181 --replication-factor 2 --partitions 1 --topic test1./kafka-console-consumer.sh --zookeeper mater:2181,hadoop2:2181,hadoop3:2181 --topiv test1#以下命令在另一台服务器中操作./kafka-console-producer.sh --broker-list hadoop1:9092,hadoop2:9092,hadoop3:9092 --topic test1 在生产者中输入文字，在消费者中查看，验证 步骤六、hive安装与配置 hive不需要任何配置就可以运行，但需配置更改mysql元数据存储 删除hdfs中的/user/hive（之前运行过hive后，才会出现此目录） 1hadoop fs -rmr /user/hive 复制hive/conf/hive-default.xml.template为hive-site.xml，然后在配置中修改： 12345678910111213141516&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://192.168.126.154:3306/hive?useSSL=false&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;account&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;password&lt;/value&gt;&lt;/property&gt; 将mysql的链接jar包拷贝到hive到lib目录下。 还有，将hive-site.xml配置文件里的 value值带：的，都改成绝对路径，否则报错，hadoop不认带：的路径。（所有的 ${system:java.io.tmpdir} 改成 /tmp/） mysql中要手动创建hive数据库 1create database hive character set latin1; 如果出现没有权限的问题，在mysql中授权（在安装mysql的机器上执行） 1mysql -r root -p 123grant all privileges on *.* to 'root'@'%' identified by 'root' with grant option;grant all privileges on *.* to 'root'@'hadoop1' identified by 'root' with grant option;flush privileges; 初始化元数据 1schematool -initSchema -dbType mysql 步骤七、hbase安装与配置 修改conf/hbase-env.sh 12export JAVA_HOME=/opt/java/jdk1.8.0_201export HBASE_MANAGES_ZK=false 修改hbase-site.xml 123456789101112131415161718&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://hadoop1:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;hadoop1:2181,hadoop2:2181,hadoop3:2181&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改conf/regionservers文件，其中配置所有hbase主机，每个主机独占一行，hbase启动或关闭时会按照此配置顺序执行。 启动 主节点： 1start-hbae.sh 在一从节点启动备用hhadoop1实现高可用： 1hbase-daemon.sh start hadoop1 关闭集群：stop-hbase.sh]]></content>
      <categories>
        <category>bigdata</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>bigdata</tag>
        <tag>environment construct</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[myabtis进阶]]></title>
    <url>%2F2018%2F11%2F17%2Fusing%2Fjava%2Fframework%2Fspringboot-myabtis%2F</url>
    <content type="text"><![CDATA[逆向工程 在数据库中建好表 配置好xml，通过逆向工程生成dao接口、实体类、xml映射文件 当需要添加数据操作的时候，先在xml中写好CRUD语句，然后在DAO接口层写接口，最后到映射文件 &emsp;&emsp;随着数据库表的增加、修改，我们需要做的修改随之增加，增加了不少的工作量。 无xml的myabtis之路 设计需要的实体类 根据实体层在数据库中建表，逆向工程在数据库中生成 当需要进行增删改查的时候，只需要在Mapper映射文件中，用对应的注解@Select、@Delete等进行相应的操作即可 &emsp;&emsp;依然没有自动生成的代码]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
        <tag>orm</tag>
        <tag>myabtis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot使用过程中踩过的坑]]></title>
    <url>%2F2018%2F11%2F05%2Fusing%2Fjava%2Fframework%2Fspringboot-question%2F</url>
    <content type="text"><![CDATA[SpringBoot项目启动过程中出现类似Could not resolve placeholder ‘td.pathprefix’ in value “${td.pathprefix}”的错误。&emsp;&emsp;问题的产生是由于有多个properties文件造成的，如果再第一个properties文件中没有找，就不认为没有了，不继续找下一个properties文件 123456@Beanpublic static PropertySourcesPlaceholderConfigurer placeholderConfigurer() &#123; PropertySourcesPlaceholderConfigurer c = new PropertySourcesPlaceholderConfigurer(); c.setIgnoreUnresolvablePlaceholders(true); return c;&#125; 项目中用到什么依赖加载什么依赖，不要一股脑都添加上去，springboot会做各种初始设置，可能引起报错]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
        <tag>bug</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sklearn学习（一）----广义线性模型]]></title>
    <url>%2F2018%2F10%2F19%2Ftheory%2Falgorithm%2Fmachinelearning%2Fsklearn%2Fsklearn-1%2F</url>
    <content type="text"><![CDATA[学习环境Windows 10 + pycharm + anaconda3 广义线性模型&emsp;&emsp;目标值y是变量x的线性组合，$\hat{y}$是预测值 \hat{y}(\omega,x)=\omega_0+\omega_1x_1+...+\omega_px_p&emsp;&emsp;定义向量 $\omega=(\omega_1,\omega_2,…,\omega_p)$作为conf_,定义 $\omega_0$作为intercept_ 普通最小二乘法&emsp;&emsp;（LinearRegression ）拟合一个带有系数 w = (w_1, …, w_p) 的线性模型，使得数据集实际观测数据和预测数据（估计值）之间的残差平方和最小。 \min_{\omega}{||X_\omega-y||_2}^2\qquad也就是求 \sum_{i=1}^{\omega}(X_i-y)^2的最小值算法复杂度：该方法使用 X 的奇异值分解来计算最小二乘解。如果 X 是一个 size 为 (n, p) 的矩阵，设 n \geq p ，则该方法的复杂度为 O(n p^2). 岭回归&emsp;&emsp;岭（Ridge）回归，又称脊回归、吉洪诺夫正则化（Tikhonov regularization），是对不适定问题（ill-posed problem)进行回归分析时最经常使用的一种正则化方法。实际上是一种最小二乘法的改良，放弃了最小二乘法的无偏性，以损失部分信息、降低精度为代价获得更为符合实际和可靠的回归系数的回归方法，对于病态数据的拟合要强于最小二乘法。岭回归通过对系数的大小施加惩罚来解决 普通最小二乘法 的一些问题。 岭系数最小化的是带罚项的残差平方和。 \min_\omega{||X_\omega-y||_2}^2+\alpha{||\omega||_2}^2其中， $\alpha \geq 0$ 是控制系数收缩量的复杂性参数： $\alpha$ 的值越大，收缩量越大，这样系数对共线性的鲁棒性也更强。 算法复杂度：该方法使用 X 的奇异值分解来计算最小二乘解。如果 X 是一个 size 为 (n, p) 的矩阵，设 n \geq p ，则该方法的复杂度为 O(n p^2). 设置正则化参数：广义交叉验证&emsp;&emsp;RidgeCV 通过内置的 Alpha 参数的交叉验证来实现岭回归。 该对象与 GridSearchCV 的使用方法相同，只是它默认为 Generalized Cross-Validation(广义交叉验证 GCV)，这是一种有效的留一验证方法（LOO-CV）: Lasso&emsp;&emsp;估计稀疏系数的线性模型。倾向于使用具有较少参数值的情况，有效地减少给定解决方案所依赖变量的数量。 因此，Lasso 及其变体是压缩感知领域的基础。 在一定条件下，它可以恢复一组非零权重的精确集. 最小化的目标函数是： \min_\omega\frac{1}{2n_{samples}}{||X_\omega-y||_2}^2+\alpha||\omega||_1&emsp;&emsp;其中，$\alpha$ 是一个常数， $||w||_1$ 是参数向量的 $\ell_1-norm$ 范数。 参考文献 http://sklearn.apachecn.org/cn/0.19.0/modules/linear_model.html#ridge-regression]]></content>
      <categories>
        <category>sklearn</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Machine Learning</tag>
        <tag>Algorithm</tag>
        <tag>sklearn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud(六) Zuul]]></title>
    <url>%2F2018%2F10%2F17%2Fusing%2Fjava%2Fframework%2Fspringcloud-6%2F</url>
    <content type="text"><![CDATA[API网关服务 ： Spring Cloud Zuul&emsp;&emsp;Spring Cloud Zuul通过与Spring Cloud Eureka进行整合，将自身注册为Eureka服务治理下的应用，同时从Eureka中获得所有其他微服务的实力信息，使得自动完成维护服务实例的工作。对于路由规则的维护，Zuul默认会通过服务名作为ContextPath的方式来创建路由映射。 &emsp;&emsp;开发者可以通过使用Zuul来创建各种检校过滤器，然后指定那些规则的请求需要执行检校逻辑，只有通过检校的才会被路由到具体的微服务里接口，否则返回错误提示。 快速入门构建网关 构建spring boot工程，引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt;&lt;/dependency&gt; 创建启动类，添加EnableZuulProxy注解开启API网关服务功能 12345678@SpringCloudApplication@EnableZuulProxypublic class ApigatewayApplication &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(ApigatewayApplication.class).web(true).run(args); &#125;&#125; 修改配置文件 12345server:port: 1501spring:application: name: api-gateway 请求路由传统路由方式/api-a-url/**的路由都会到http://localhost:8080/；如：访问http://localhost:1501/api-a-url/hello会到http://localhost:8080/hello 12345zuul: routes: api-a-url: path: /api-a-url/** url: http://localhost:8080/ 面向服务的路由&emsp;&emsp;具体的路由由Eureka服务发现机制负责自动维护 添加Eureka的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; 配置服务路由 12345678zuul: routes: api-b: path: /api-a/** serviceId: hello-service api-b: path: /api-b/** serviceId: feign-consurme 请求过滤&emsp;&emsp;继承ZuulFilter抽象类并实现定义的4个抽象函数就可以完成对请求的拦截和过滤。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Log4jpublic class RoleFilter extends ZuulFilter &#123; /** * 过滤器类型，决定过滤器在请求的哪个周期中执行 * 定义为pre，在请求被路由之前执行 */ @Override public String filterType() &#123; return "pre"; &#125; /** * 过滤器的执行顺序，当一个阶段中存在多个过滤器的时候，根据该方法返回值一次执行 */ @Override public int filterOrder() &#123; return 0; &#125; /** * 判断该过滤器是否需要执行。这里我们直接返回true，因此该过滤器对所有请求都生效。实际中利用该函数来指定过滤器的有效范围 */ @Override public boolean shouldFilter() &#123; return true; &#125; /** * 过滤器的具体逻辑 */ @Override public Object run() throws ZuulException &#123; RequestContext currentContext = RequestContext.getCurrentContext(); HttpServletRequest request = currentContext.getRequest(); log.info(String.format("send %s request to %s",request.getMethod(),request.getRequestURL().toString())); String accessToken = request.getParameter("accessToken"); if (accessToken == null) &#123; log.warn("access token is empty"); currentContext.setSendZuulResponse(false); //设置不对其进行路由 currentContext.setResponseStatusCode(401); //设置错误返回码 currentContext.setResponseBody("没有access token"); //设置返回的body内容 return null; &#125; log.info("access token ok"); return null; &#125;&#125; &emsp;&emsp;设置具体的配置类配置bean 1234567@Configurationpublic class FilterConfig &#123; @Bean public RoleFilter roleFilter() &#123; return new RoleFilter(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Spring Cloud</tag>
        <tag>Microservice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习（二）---- 单变量线性回归]]></title>
    <url>%2F2018%2F10%2F15%2Ftheory%2Falgorithm%2Fmachinelearning%2Fmachinelearning-2%2F</url>
    <content type="text"><![CDATA[模型表示&emsp;&emsp;在监督学习中，有一个数据集，这个数据集被称为训练集。 例&emsp;&emsp;以房屋交易为例，假如我们的Training Set（训练集）如表 Size in feet2(x) Price($) in 1000's(y) 2104 460 1416 232 1534 315 852 178 ... ... &emsp;&emsp;&emsp;&emsp;m代表训练集中的实例数目&emsp;&emsp;&emsp;&emsp;x代表特征/输入变量&emsp;&emsp;&emsp;&emsp;y代表目标变量/输出变量&emsp;&emsp;&emsp;&emsp;(x,y)代表训练集中的实例&emsp;&emsp;&emsp;&emsp;$(x^{(i)},y^{(i)})$代表第i个观察实例&emsp;&emsp;&emsp;&emsp;h代表学习算法的解决方案或函数也称为假设（Hypothesis）&emsp;&emsp;h的一种可能的表达式 $h(x)=\theta_0+\theta_1(x)$,即单变量线性回归 代价函数&emsp;&emsp;代价函数，有时候也称为平方误差函数/平方误差代价函数 例J(θ_0,θ_1)=\frac{1}{2m}\sum_{i=1}^m (h_\theta(x^{(i)}-y^{(1)}))^2注：$J(θ_0,θ_1)$就是代价函数（cost function）&emsp;&emsp;m:样本空间容量$h_\theta(x^{(i)})=\theta_0+\theta_1(x^{(i)})$ $^{minimize}_{θ_0,θ_1}J(θ_0,θ_1)$既是我们所想达到的目的 梯度下降算法\theta_j := \theta_j-\alpha \frac{\partial}{\partial \theta_j}J(θ_0,θ_1)\qquad(for\;i = 0\;and\;j =1)注：$\alpha$为一个数字，代表学习效率；如果太大，会导致结果不准确甚至无法收敛；如果太小，会导致算法效率低下。 注意：$\theta_0:=\theta_0 , \theta_1:=\theta_1$应该同时更新 也就是：&emsp;&emsp;$temp0 = \theta_0 -\alpha \frac{\partial}{\partial \theta_0}J(θ_0,θ_1)$&emsp;&emsp;$temp1 = \theta_1 -\alpha \frac{\partial}{\partial \theta_1}J(θ_0,θ_1)$&emsp;&emsp;$\theta_0:=temp0$&emsp;&emsp;$\theta_1:=temp1$ 对上述化简计算可得梯度下降算法 : \theta_0:=\theta_0-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})\theta_1:=\theta_1-\alpha\frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x^{(i)}梯度下降，随机梯度下降和批量梯度下降以及小批量梯度下降的联系与区别。&emsp;&emsp; 批量梯度下降：&emsp;&emsp;使误差函数尽可能的小，每次迭代需要整个样本来对参数进行更新，当样本数目变大时，训练速度回逐渐变慢 随机梯度下降：&emsp;&emsp;不同于批量梯度下降，随机梯度下降是每次迭代使用一个样本来对参数进行更新。使得训练速度加快，但是准确度会降低 小批量梯度下降：&emsp;&emsp;是对批量梯度下降以及随机梯度下降的一个折中办法。其思想是：每次迭代 使用batch_size个样本来对参数进行更新。 batcha_size的选择带来的影响： 在合理地范围内，增大batch_size的好处：a. 内存利用率提高了，大矩阵乘法的并行化效率提高。b. 跑完一次 epoch（全数据集）所需的迭代次数减少，对于相同数据量的处理速度进一步加快。c. 在一定范围内，一般来说 Batch_Size 越大，其确定的下降方向越准，引起训练震荡越小。 盲目增大batch_size的坏处：a. 内存利用率提高了，但是内存容量可能撑不住了。b. 跑完一次 epoch（全数据集）所需的迭代次数减少，要想达到相同的精度，其所花费的时间大大增加了，从而对参数的修正也就显得更加缓慢。c. Batch_Size 增大到一定程度，其确定的下降方向已经基&gt;本不再变化。]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Machine Learning</tag>
        <tag>AI</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习（一）---初识]]></title>
    <url>%2F2018%2F10%2F15%2Ftheory%2Falgorithm%2Fmachinelearning%2Fmachinelearning-1%2F</url>
    <content type="text"><![CDATA[什么是机器学习？ 在没有明确设置的情况下，使得计算机具有学习能力的研究领域。 ----Arthur Samuel&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; 一个程序被认为能从经验E中学习，解决任务T，达到性能度量值P，当且仅当，有了经验E，经过P评判，程序在处理T时的性能有所提升。 ----Tom Mitchell&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; 什么是监督学习？&emsp;&emsp;给算法一个数据集，该数据集内包含有正确的答案，让算法给出更多的准确答案。 属性（特征）&emsp;&emsp;一般来说，一个学习问题通常会考虑一系列 n 个 样本 数据，然后尝试预测未知数据的属性。 如果每个样本是 多个属性的数据 （比如说是一个多维记录），就说它有许多“属性”，或称 features(特征) 。 回归问题&emsp;&emsp;回归指的是，我们在试着推测出一系列的连续值属性。&emsp;&emsp;回归问题的一个例子是预测鲑鱼的长度是其年龄和体重的函数。 分类问题&emsp;&emsp;分类指的是，样本属于两个或更多个类，我们想从已经标记的数据中学习如何预测未标记数据的类别。&emsp;&emsp;分类问题的一个例子是手写数字识别，其目的是将每个输入向量分配给有限数目的离散类别之一。 我们通常把分类视作监督学习的一个离散形式（区别于连续形式），从有限的类别中，给每个样本贴上正确的标签。 什么是无监督学习？&emsp;&emsp;给算法一个数据集，让算法自动的将该数据集分成n类。（与监督学习不同，数据集没有任何的标签：或者有相同的标签；或者没有标签）。&emsp;&emsp; 其中训练数据由没有任何相应目标值的一组输入向量x组成。这种问题的目标可能是在数据中发现彼此类似的示例所聚成的组，这种问题称为 聚类 , 或者，确定输入空间内的数据分布，称为 密度估计 ，又或从高维数据投影数据空间缩小到二维或三维以进行 可视化。 无监督学习的应用领域&emsp;&emsp;社交网络分析、细分市场、天文数据分析、组织大型计算机集群等 什么是加速比&emsp;&emsp;一个程序的串行版本的运行时间和他的并行版本的运行时间的比值。]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Machine Learning</tag>
        <tag>AI</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud(五) Feign]]></title>
    <url>%2F2018%2F10%2F15%2Fusing%2Fjava%2Fframework%2Fspringcloud-5%2F</url>
    <content type="text"><![CDATA[声明式服务调用 ：Spring Cloud Feign&emsp;&emsp;Spring Cloud Feign基于Netflix Feign实现，整合了Spring Cloud Ribbon和Spring Cloud Hystrix，除此之外，还提供了一种声明式的Web服务端定义方式。 快速入门 引入POM依赖 123456789101112131415161718&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Edgware.SR4&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 创建启动类，并添加EnableFeignClients注释开启Spring Cloud Feign支持 123456789@SpringBootApplication@EnableFeignClients@EnableDiscoveryClientpublic class FeignconsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(FeignconsumerApplication.class, args); &#125;&#125; 编写HelloService接口,通过FeignClient注解指定服务名来绑定服务，然后通过SpringMVC注解来绑定具体该服务提供的REST接口 12345@FeignClient("hello-service") public interface HelloService &#123; @RequestMapping("/hello") String hello(); &#125; 编写Controller层，调用HelloService接口 12345678910111213141516@RestControllerpublic class HelloController &#123; private final HelloService helloService; @Autowired public HelloController(HelloService helloService) &#123; this.helloService = helloService; &#125; @RequestMapping(value = "/feign-consumer", method = RequestMethod.GET) public String helloConsumer () &#123; return helloService.hello(); &#125;&#125; 修改配置文件 123456789server: port: 1401spring: application: name: feign-consumereureka: client: serviceUrl: defaultZone: http://localhost:1111/eureka/ 通过浏览http://localhost:1111/可以查看注册中心新增了feign-consumer,通过访问http://localhost:1401/feign-consumer查看结果 参数绑定&emsp;&emsp;与SpringMVC不同，FeignClient中绑定参数必须通过value属性指定具体的参数名，不然会抛出IllegalStateException异常，value属性不能为空。 12345678910111213141516@FeignClient("hello-service")public interface HelloService &#123; @RequestMapping("/hello") String hello(); @RequestMapping(value = "/hello1", method = RequestMethod.GET) String hello(@RequestParam("name") String name); @RequestMapping(value = "/hello2", method = RequestMethod.GET) User hello(@RequestParam("name") String name, @RequestParam("age") Integer age); @RequestMapping(value = "/hello3", method = RequestMethod.POST) String hello(@RequestBody User user);&#125; 继承特性&emsp;&emsp;可以将项目中的几个子系统的共同部分抽象出来作为一个子项目，在maven中使用依赖减少代码量，但是同时会导致项目耦合度增加，需要严格按照面向对象的开闭原则，，否则可能出现牵一发而动全身的后果，增加不必要的维护工作量。 Ribbon配置&emsp;&emsp;Spring Cloud Feign的客户端负载均衡是通过Spring Cloud Ribbon实现的，因此可以通过直接配置Ribbon客户端来实现自定义各个服务端调用的参数。 Ribbon全局配置1234ribbon: ConnectTimeout: 500 ReadTimeout: 500 指定服务配置&emsp;&emsp;在使用Spring Cloud Feign的时候，针对各个服务客户端进行个性化配置的方式和Ribbon一致，都是\.ribbon.key=value,client是@FeignClient(value=”value”)中的value设置值。在我们使用@FeignClient(value=”value”)的同时创建了一个名为value的Ribbon客户端。 1234567hello-service: #对value为hello-service的客户端进行设置 ribbon: ReadTimeout: 2000 OkToRetryOnAllOperation: true MaxAutoRetriesNextServer: 2 MaxAutoRetries: 1 重试机制&emsp;&emsp;在Spring Cloud Feign中，默认实现了请求的重试机制，上面的配置中我们已经做了相应配置 Hystrix设置&emsp;&emsp;默认情况下，Spring Cloud Feign会将所有Feign客户端的方法都封装到Hystrix命令中进行服务保护。 Hystrix全局配置12345678910111213hystrix: command: default: # execution: # timeout: # enabled: false #关闭熔断功能 isolation: thread: timeoutInMilliseconds: 5000#feign:# hystrix:# enabled: false #关闭Feign对Hystrix的支持 某个客户端关闭Hystrix&emsp;&emsp;需要通过使用@Scope(“properte”)注解为指定的客户端配置Feign.Builder实例。 12345678910111213141516//配置类 DisableHystrixConfig.java@Configurationpublic class DisableHystrixConfig &#123; @Bean @Scope("prototype") public Feign.Builder feignBuilder() &#123; return Feign.builder(); &#125;&#125;//对某个服务关闭Hystrix@FeignClient(value = "hello-service",configuration = DisableHystrixConfig.class)public interface HelloService &#123; ...&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Spring Cloud</tag>
        <tag>Microservice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud(四) Hystrix]]></title>
    <url>%2F2018%2F10%2F13%2Fusing%2Fjava%2Fframework%2Fspringcloud-4%2F</url>
    <content type="text"><![CDATA[服务容错保护： Spring Cloud Hystrix&emsp;&emsp;在微服务架构中，我们将系统拆分为很多服务单元，因为各单元的应用间通过服务注册与订阅的方式相互依赖，并且各单元运行在不同的进程中，因此有可能因为网络原因或者自己问题出现调用服务故障或者延迟。随着服务数量的增加，故障亦随之累加，最后导致自身服务的瘫痪。为了解决这种问题，出现了断路器等一系列的保护机制。而Spring Cloud Hystrix就实现了断路器、线程隔离等一系列系统保护功能，为系统的延迟和故障提供更加强大的容错能力。 实现容错保护 引入POM依赖 12345&lt;!--Hystrix依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 修改java类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465//启动类 RibbonconsumerApplication.java@SpringBootApplication@EnableDiscoveryClient //开启服务发现功能@EnableCircuitBreaker //开启断路器功能//@SpringCloudApplication //该注释包含了以上三个注释（一个SpringCloud标准应用包含服务发现以及断路器）public class RibbonconsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RibbonconsumerApplication.class, args); &#125;&#125;//Service层 service/impl/HelloServiceImpl.java@Servicepublic class HelloServiceImpl implements HelloService &#123; private final RestTemplate restTemplate; @Autowired public HelloServiceImpl(RestTemplate restTemplate) &#123; this.restTemplate = restTemplate; &#125; @Override @HystrixCommand(fallbackMethod = "helloFallback") public String helloService() &#123; return restTemplate.getForEntity("http://hello-service/hello", String.class).getBody(); &#125; public String helloFallback() &#123; return "error"; &#125;&#125;//Controller controller/ConsumerController.java@RestControllerpublic class ConsumerController &#123; private final RestTemplate restTemplate; private final HelloService helloService; @Autowired public ConsumerController(RestTemplate restTemplate, HelloService helloService) &#123; this.restTemplate = restTemplate; this.helloService = helloService; &#125; @RequestMapping(value = "/ribbon-consumer", method = RequestMethod.GET) public String helloConsumer() &#123; return restTemplate.getForEntity("http://hello-service/hello", String.class).getBody(); &#125; @RequestMapping(value = "/ribbon-consumer-hello-service", method = RequestMethod.GET) public String helloConsumerByHelloService() &#123; return helloService.helloService(); &#125; @RequestMapping(value = "/hello", method = RequestMethod.GET) public String hello() &#123; return "Hello World"; &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Spring Cloud</tag>
        <tag>Microservice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud(三) Ribbon]]></title>
    <url>%2F2018%2F10%2F12%2Fusing%2Fjava%2Fframework%2Fspringcloud-3%2F</url>
    <content type="text"><![CDATA[客户端负载均衡： Spring Cloud Ribbon&emsp;&emsp;Spring Cloud Ribbon是一个基于HTTP和TCP的客户端负载均衡工具，它基于Hetflix Ribbon实现。 客户端负载均衡&emsp;&emsp;负载均衡是对一个系统的高可用、网络压力的缓解、和处理能力扩容的重要手段之一。通常说的负载均衡都指的是服务端负载均衡，主要分为软件负载均衡和硬件负载均衡。硬件负载均衡主要通过在服务器节点之间安装专门用于负载均衡的设备，比如F5。而软件负载均衡则是通过在服务器中安装一些具有负载均衡功能或者模块的软件来完成请求分发工作，比如Nginx。服务端负载均衡都是维护一个下挂可用的服务器清单，通过某种算法（轮询、按照权重、按照流量等）从可用的服务器清单中取出一台服务器的地址，然后进行转发。客户端负载均衡不同与服务端负载均衡的是所有的客户端都要维护自己要访问的服务器清单，这些清单都来自于注册中心。 Spring Cloud Ribbon使用客户端负载均衡 服务提供者只需要启动多个服务实例并注册一个注册中心或者多个相关联的服务注册中心 服务注册者直接通过调用被@LoadBalanced注解修饰过的RestTemplate来实现面向服务的接口调用。 RestTemplate详解GET请求（2种方法）getForEntity函数&emsp;&emsp;该方法返回ResponseEntity（Spring对HTTP请求相应的封装） getForEntity(String url, Class responseType, Object… uriVariables) url : 请求的地址 responseType : 请求响应体body的包装类型 uriVariables : url中的参数绑定，数组内容替代{1}这样的占位符。 例： 1getForEntity("http://USER-SERVICE/user?name=&#123;1&#125;",String.class,"didi"); getForEntity(String url, Class responseType, Map uriVariables) 与1中只有uriVariables不同，替代的是制定参数的{key}这样的占位符。 例: 1getForEntity("http://USER-SERVICE/user?name=&#123;name&#125;",String.class,new HashMap&lt;&gt;().put("name","peter")); getForEntity(URI url, Class responseType) 使用URI（统一资源标识符）来代替url getForObject函数&emsp;&emsp;可以认为是getForEntity的进一步封装，通过HttpMessageConverterExtractor对HTTP的请求响应体进行对象转换。 getForObject(String url, Class responseType, Object… uriVariables) getForObject(String url, Class responseType, Map uriVariables) getForObject(URI url, Class responseType) POST请求（3种方法）posrFotEntity函数&emsp;&emsp;绝大部分和getForEntity用法相同 postForEntity(String url, Object request, Class responseType, Object… uriVariables)request : 可以是一个普通对象（REstTemlate会将其转化成一个HttpEntity来处理，类型为Object，request的内容被视为body内容），也可以是一个HttpEntity对象（完整的Http请求，包含body和header） postForEntity(String url, Object request, Class responseType, Map uriVariables) postForEntity(URI url, Object request, Class responseType) postForObject函数&emsp;&emsp;与getForObject类似 postForLocation函数&emsp;&emsp;以POST方式提交资源，并返回新资源的URI。因为返回新资源的URI，因此不需要指定responseType。 postForLocation(String url, Object request, Object… uriVariables) postForLocation(String url, Object request, Map uriVariables) postForLocation(URI url, Object request) PUT请求put函数&emsp;&emsp;put方法无返回值，因此也就没有responseType，其他与postForObject类似 put(String url, Object request, Object… uriVariables) put(String url, Object request, Map uriVariables) put(URI url, Object request) DELETE请求delete函数&emsp;&emsp;通常使用唯一标识，因此无需request的body信息。 delete(String url, Object… uriVariables) delete(String url, Map uriVariables) delete(URI url)]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Spring Cloud</tag>
        <tag>Microservice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud(二) Eureka]]></title>
    <url>%2F2018%2F10%2F11%2Fusing%2Fjava%2Fframework%2Fspringcloud-2%2F</url>
    <content type="text"><![CDATA[服务治理：Spring Cloud Eureka&emsp;&emsp;Spring Cloud Eureka是Spring Cloud Netflix的一部分，它是基于Netflix Eureka 做了二次的封装，主要完成微服务的服务治理功能。 服务治理&emsp;&emsp;服务治理可以说是微服务架构中的最核心和最基础的模块，它主要用来实现各个微服务实例的自动化注册和发现。 为什么需要服务治理&emsp;&emsp;随着业务的发展，系统功能越来越复杂，相应的微服务不断增加，使用静态配置的话，就会变得越来越难以维护，并且面对不断发展业务，群集规模、服务位置、服务命名规则可能发生变化。 服务注册&emsp;&emsp;在服务治理治理框架中，通常都会构建一个注册中心，每个服务单元向注册中心登记自己提供的服务，将主机与端口号、版本号、通信协议等一些附加信息告知注册中心，而注册中心形成一种清单来存储这些信息。另外，服务注册中心还需要以心跳的方式来监测清单中的服务是否可用，不可用则需要从清单中剔除。 服务发现&emsp;&emsp;在服务治理框架下运转，服务间的调用不再通过具体的实例地址来实现，通过向服务名发起请求调用实现。因此，服务调用方在发起调用的时候并不知道服务实例的位置，因此，调用方需要向注册中心发出咨询服务来获取服务实例清单，以实现对具体服务实例的访问。 Eureka和RibbonEureka服务端&emsp;&emsp;Eureka服务端，亦称之为服务注册中心，同其他服务注册中心一样，支持高可用配置。它依托于强一致性提供良好的服务实例可用性，可以应对多种不同的故障场景。 搭建服务注册中心 创建SprinBoot工程（略），在此，我命名为eurekaserver，添加maven依赖 1234567891011121314151617181920212223242526&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Edgware.SR4&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 通过注解EnableEurekaServer启动一个注册服务中心提供给其他应用进行对话 1234567@SpringBootApplication@EnableEurekaServerpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125;&#125; 默认配置下，该注册服务中心会将自己作为客户端来尝试注册他自己，通过配置application.yml/application.properties来增加配置来禁用它的客户端注册行为。 12345678910server: port: 1111 #在同一个服务器下进行学习测试，需要修改端口eureka: instance: hostname: localhostclient: register-with-eureka: false #设置为false，不向注册中心注册自己 fetch-registry: false #注册中心的职责是维护服务实例，因此不需要去检索服务 serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 通过浏览http://localhost:1111/可以查看注册中心的控制台信息 高可用注册中心&emsp;&emsp;在微服务架构的分布式环境中，我们需要充分考虑发生故障的情况，所以在生产中我们需要进行高可用部署。对于服务中心，亦是如此。&emsp;&emsp;Eureka Server设计之初就好率了高可用的问题，在Eureka的服务治理设计中，所有节点既是服务提供方，也是服务消费方，Eureka Server的高可用实际上就是将自己做为服务向其他注册中心注册自己 ，形成一组互相注册的服务注册中心，实现服务清单的互相同步，实现高可用的效果。 在以前搭建注册中心的基础上，添加application-peer1.yml和application-peer2.yml 1234567891011121314151617181920212223##### application-peer1.ymlserver:port: 1111 #在同一个服务器下进行学习测试，需要修改端口eureka:instance: hostname: peer1client: register-with-eureka: false #设置为false，不向注册中心注册自己 fetch-registry: false #注册中心的职责是维护服务实例，因此不需要去检索服务 serviceUrl: defaultZone: http://peer2:1112/eureka/##### application-peer2.ymlserver:port: 1112 #在同一个服务器下进行学习测试，需要修改端口eureka:instance: hostname: peer2client: register-with-eureka: false #设置为false，不向注册中心注册自己 fetch-registry: false #注册中心的职责是维护服务实例，因此不需要去检索服务 serviceUrl: defaultZone: http://peer1:1111/eureka/ 因为在同一台服务器下操作，需要在hosts文件中添加peer1和peer2的转换，修改/etc/hosts,新增以下内容 12127.0.0.1 peer1127.0.0.1 peer2 通过spring.profiles.active属性分别启动peer1和peer2，启动指令 12java -jar eurekserver-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer2java -jar eurekserver-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer1 Eureka客户端&emsp;&emsp;Eureka客户端，主要处理服务的注册与发现，Eureka客户端向注册中心注册自身提供的服务并周期性地发送心跳来更新它的租服务租约，同时，他也能从服务段查询当前注册的服务信息并把它们缓存到本地并周期性地刷新服务状态。 注册服务提供 创建SprinBoot工程（略），在此，我命名为eurekaclient，添加maven依赖 1234567891011121314151617181920212223242526272829303132333435&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Edgware.SR4&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 编写/hello请求处理接口，在日志中打印出服务相关 1234567891011121314151617181920212223242526272829303132333435363738394041@RestController@Log4jpublic class HelloController &#123; @Resource private DiscoveryClient client; @Resource private Registration registration; @RequestMapping(value = "/hello", method = RequestMethod.GET) public String index() &#123; //getLocalServiceInstance 方法已经过时，可以采用下边的testBalance ServiceInstance instance = client.getLocalServiceInstance(); log.info( "/test, host:" + instance.getHost() + ", service_id:" + instance.getServiceId() ); return "From Service-A"; &#125; @RequestMapping(value = "/testBalance", method = RequestMethod.GET) public String testBalance(@RequestParam String param) &#123; ServiceInstance instance = serviceInstance(); String result = "/testBalance, host:port=" + instance.getUri() + ", " + "service_id:" + instance.getServiceId(); log.info(result); return "From Service-A , " + result; &#125; public ServiceInstance serviceInstance() &#123; List&lt;ServiceInstance&gt; list = client.getInstances(registration.getServiceId()); if (list != null &amp;&amp; list.size() &gt; 0) &#123; for(ServiceInstance itm : list)&#123; if (itm.getPort() == 2001) &#123; return itm; &#125; &#125; &#125; return null; &#125;&#125; 在启动类上添加EnableDiscoveryClient注释，激活Eureka中的DiscoveryClient实现 1234567@SpringBootApplication@EnableDiscoveryClientpublic class EurekaclientApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaclientApplication.class, args); &#125;&#125; 修改配置文件 123456789server: port: 1211 #因为在同一台服务器下学习测试，需要修改端口spring: application: name: hello-service #为服务命名eureka: client: serviceUrl: defaultZone: http://localhost:1111/eureka/ # 指定注册中心的地址 通过浏览http://localhost:1111/可以查看注册中心中有hello-service，在注册中心的日志中可以发现 12018-10-12 04:07:43.379 INFO 11069 --- [nio-1111-exec-5] c.n.e.registry.AbstractInstanceRegistry : Registered instance HELLO-SERVICE/bogon:hello-service:1211 with status UP (replication=false) 访问http://localhost:1211/hello之后，可以在控制台中发现以下日志信息 12018-10-12 04:19:53.087 INFO 11306 --- [nio-1211-exec-1] x.z.e.controller.HelloController : /test, host:bogon, service_id:hello-service 服务发现与消费&emsp;&emsp;服务消费者，主要完成发现服务以及服务消费。其中，发现服务由Eureka客户端完成，而服务消费则由Ribbon完成。 Ribbon&emsp;&emsp;Ribbon是一个基于HTTP和TCP的客户端负载均衡器，它可以通过客户端中配置的ribbonServerList服务端列表去轮询访问以达到负载均衡的作用；当Ribbon和Eureka联合使用，Ribbon的服务清单RibbonServerList会被DiscoveryEnableNIWSServerList重写，扩展成从Eureka注册中心来获取服务列表，同时，它也会用NIWSDiscoveryPing来代替IPing，将职责委托给Eureka来确定服务端是否已经启动。 服务发现与服务消费示例 启动之前的服务注册中心，启动两个hello-service 1234567#启动注册服务中心nohup java -jar /opt/eureka-server/eurekserver-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer1 &gt; /opt/log/out-eureka-server-peer1.log &amp;nohup java -jar /opt/eureka-server/eurekserver-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer2 &gt; /opt/log/out-eureka-server-peer2.log &amp;#启动两个hello-servicenohup java -jar eurekaclient-0.0.1-SNAPSHOT.jar --server.port=1201 &gt; /opt/log/out-eureka-client-1201.log &amp;nohup java -jar eurekaclient-0.0.1-SNAPSHOT.jar --server.port=1202 &gt; /opt/log/out-eureka-client-1202.log &amp; 创建SprinBoot工程（略），取名为sibbon-consumer，并引入以下依赖 123456789101112131415161718&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Edgware.SR4&lt;/spring-cloud.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在启动类上添加EnableDiscoveryClient注释，启动服务发现功能，编写配置类开启客户端负载均衡,编写controller实现ribbon-consumer接口 12345678910111213141516171819202122232425262728293031//项目启动类 RibbonconsumerApplication.java@SpringBootApplication@EnableDiscoveryClientpublic class RibbonconsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RibbonconsumerApplication.class, args); &#125;&#125;//配置类 config/LoadBalanceConfig.java@Configurationpublic class LoadBalanceConfig &#123; @Bean @LoadBalanced //开启客户端负载均衡 RestTemplate restTemplate() &#123; return new RestTemplate(); &#125;&#125;//实现ribbon-consumer接口的 controller/ConsumerController.java@RestControllerpublic class ConsumerController &#123; @Resource private RestTemplate restTemplate; @RequestMapping(value = "/ribbon-comsumer", method = RequestMethod.GET) public String helloConsumer() &#123; return restTemplate.getForEntity("http://HELLO-SERVICE/hello", String.class).getBody(); &#125;&#125; 修改配置文件 123456789server:port: 1301spring:application: name: ribbon-consumereureka:client: serviceUrl: defaultZone: http://localhost:1111/eureka/ 启动项目，查看http://localhost:1301/ribbon-consumer,通过两个hello-service的日志可以看到确实是轮询实现的负载均衡 项目代码地址Github]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Spring Cloud</tag>
        <tag>Microservice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud(一) 简介]]></title>
    <url>%2F2018%2F10%2F11%2Fusing%2Fjava%2Fframework%2Fspringcloud-1%2F</url>
    <content type="text"><![CDATA[Spring Cloud简介 什么是微服务（Microservice） &emsp;&emsp;微服务英文名称Microservice，Microservice架构模式就是将整个Web应用组织为一系列小的Web服务。这些小的Web服务可以独立地编译及部署，并通过各自暴露的API接口相互通讯。它们彼此相互协作，作为一个整体为用户提供功能，却可以独立地进行扩展。由于有了轻量级的通信协作基础，所以这个微服务可以通过不同的语言进行开发编写。 &emsp;&emsp;目前主流的微服务框架：Dubbo、 Spring Cloud、thrift、Hessian等。 微服务框架适合的场景 我们把整个系统根据业务拆分成几个子系统。 每个子系统可以部署多个应用，多个应用之间使用负载均衡。 需要一个服务注册中心，所有的服务都在注册中心注册，负载均衡也是通过在注册中心注册的服务来使用一定策略来实现。 所有的客户端都通过同一个网关地址访问后台的服务，通过路由配置，网关来判断一个URL请求由哪个服务处理。请求转发到服务上的时候也使用负载均衡。 服务之间有时候也需要相互访问。例如有一个用户模块，其他服务在处理一些业务的时候，要获取用户服务的用户数据。 需要一个断路器，及时处理服务调用时的超时和错误，防止由于其中一个服务的问题而导致整体系统的瘫痪。 还需要一个监控功能，监控每个服务调用花费的时间等。 初探Spring Cloud&emsp;&emsp;Spring Cloud是一个基于Spring Boot实现的微服务架构开发工具，为微服务架构中的配置管理、服务治理、断路器、智能路由、微代理、控制总线、全局锁、决策竞选、分布式会话和集群状态管理等操作提供了一种简单的开发方式。&emsp;&emsp;Spring Cloud包含多个子项目： Spring Cloud Config 配置管理工具，支持使用git存储配置内容，并支持客户端配置信息刷新、加密/解密配置内容等。 Spring Cloud Netflix 核心组件，对多个Netflix进行整合。 Eureka 服务治理组件，包含服务注册中心、服务注册与发现机制的实现 Hystrix 容错管理组件，实现断路器模式，帮助服务依赖中出现的延迟启动和为故障提供强大的容错能力。 Ribbon 客户端负载均衡的服务调用组件 Feign 基于 Ribbon和Hystrix的声明式服务调用组件 Zuul 网关组件，提供智能路由、过滤访问等功能 Archaius 外部化配置组件 Spring Cloud Bus 事件、消息总线，用于传播集群中的状态变化或者事件，以触发后续的处理，比如来动态刷新配置 Spring Cloud Cluster 针对ZooKeeper、Redis、Hazelacst、Consul的选举算法和通用状态模式的实现 Spring Cloud Cloudfoundry 与Pivotal Cloudfoundry的整合支持 Spring Cloud Consul 服务发现与配置管理工具 Spring Cloud Stream 通过Redis、Rabbit或者Kafka实现的消费微服务，可以通过简单的声明式模型来发送和接受消息。 Spring Cloud AWS 简化整合aws的组件 Spring Cloud Security 安全工具包，提供Zuul代理中对于OAuth2客户端请求中的中继器 Spring Cloud Sleuth Spring Cloud应用的分布式跟踪实现，可以完美整合ZipKin Spring Cloud ZooKeeper 基于ZooKeeper的服务发现与配置管理组件 Spring Cloud Starters Spring Cloud的基础组件，基于Spring Boot风格项目的基础依赖模块 Spring Cloud CLI 用于Groovy中快速创建Spring Boot项目的Spring Boot CLI插件 …]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Spring Cloud</tag>
        <tag>Microservice</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mariadb使用记录]]></title>
    <url>%2F2018%2F09%2F29%2Fusing%2Fdb%2Fnosql%2Fmariadb-using%2F</url>
    <content type="text"><![CDATA[MariaDB简介&emsp;&emsp;MariaDB数据库管理系统是MySQL的一个分支，主要由开源社区在维护，采用GPL授权许可 MariaDB的目的是完全兼容MySQL，包括API和命令行，使之能轻松成为MySQL的代替品。在存储引擎方面，使用XtraDB（英语：XtraDB）来代替MySQL的InnoDB。 安装与配置&emsp;&emsp;记录Mariadb的安装配置过程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859yum -y install mariadb mariadb-server #安装mariadb的客户端与服务端systemctl start mariadb # 启动mariadbmysql_secure_installation # 进行初始的设置# NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB# SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY!# In order to log into MariaDB to secure it, we'll need the current# password for the root user. If you've just installed MariaDB, and# you haven't set the root password yet, the password will be blank,# so you should just press enter here.# Enter current password for root (enter for none): #默认无密码登录# OK, successfully used password, moving on...# Setting the root password ensures that nobody can log into the MariaDB# root user without the proper authorisation.# Set root password? [Y/n] y # 是否设置新的root密码# New password: # Re-enter new password: # Password updated successfully!# Reloading privilege tables..# ... Success!# By default, a MariaDB installation has an anonymous user, allowing anyone# to log into MariaDB without having to have a user account created for# them. This is intended only for testing, and to make the installation# go a bit smoother. You should remove them before moving into a# production environment.# Remove anonymous users? [Y/n] Y # 是否删除匿名用户# ... Success!# Normally, root should only be allowed to connect from 'localhost'. This# ensures that someone cannot guess at the root password from the network.# Disallow root login remotely? [Y/n] n # 是否禁止root账户远程登录# ... skipping.# By default, MariaDB comes with a database named 'test' that anyone can# access. This is also intended only for testing, and should be removed# before moving into a production environment.# Remove test database and access to it? [Y/n] n # 是否删除test数据库# ... skipping.# Reloading the privilege tables will ensure that all changes made so far# will take effect immediately.# Reload privilege tables now? [Y/n] y # 是否重新加载权限表# ... Success!# Cleaning up...# All done! If you've completed all of the above steps, your MariaDB# installation should now be secure.# Thanks for using MariaDB! 远程登录设置1mysql -uroot -p #登录mysql 12GRANT ALL ON database_name.table_name TO databaseuser@&apos;ip_address&apos; IDENTIFIED BY &apos;password&apos;;flush privileges; #重新加载权限表 database_name 你要访问的数据库名称（*代表所有） table_name 你要访问的表名（*代表所有） databaseuser 新的数据库用户 password 设置新的密码（mysql将会对你的设置进行加密再到user表中） ip_address 可访问的ip地址（使用%可以让所有的IP都可以访问）]]></content>
      <categories>
        <category>datebase</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>datebase</tag>
        <tag>mysql</tag>
        <tag>mariadb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Namespace简介]]></title>
    <url>%2F2018%2F09%2F28%2Ftheory%2Flinux%2Flinux-namespace-interface%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;Namespace是将内核的全局资源做封装，使得每个Namespace都有一份独立的资源，因此，不同的进程在各自的namespace内对同一资源的使用不会产生相互干扰。&emsp;&emsp;目前，linux内核总共实现了6中namespace： IPC ： 隔离System V IPC 和POSIX消息队列&emsp;&emsp;IPC：Inter-Process Communication（进程间通信）,IPC namespace针对的是SystemV IPC和Posix消息队列，这些IPC机制都会用到标识符。IPC Namespace 能做到的就是使相同的标识符在两个Namespace中代表不同的消息队列，这样就使得两个Namespace中的进程不能通过IPC进程通信了。 Network ：隔离网络资源&emsp;&emsp;每个Network Namespace都有自己的网络设备、IP地址、路由表、/proc/net目录，端口号等 1234ip nets add new_ns #创建network namespaceip nets exec new_ns ip link list #使用 ip nets exec可以对特定的network namespace执行网络管理ip nets exec new_ns ip link set dev lo up #启用lopopback接口ip nets delete new_ns #删除namespace Mount ： 隔离文件系统挂载点&emsp;&emsp;用来隔离文件系统挂载点，每个进程能看到的文件系统都记录在/proc/$$/mounts里，在创建了一个新的Mount Namespace后，进程系统对文件系统挂载/卸载的动作不会影响到其他Namespace。 PID ： 隔离进程ID&emsp;&emsp;用于隔离进程PID号，这样一来，不同的Namespace中的进程PID号就可以是一样的了 UTS ： 隔离主机名和域名&emsp;&emsp;因为主机名可以代替IP，因此可以使用主机名在网络上访问某台机器，如果不做隔离，这个机制在容器里就会出问题。 User ：隔离用户ID和组ID&emsp;&emsp;一个进程在namespace里的用户和组ID与它在host里的ID可以不一样，最有用的地方在于可以在容器内部启用0号用户（root），但是它的特权被限定在容器内，离开容器就只是普通用户权限了]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>kernel</tag>
        <tag>namespace</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cgroup简介]]></title>
    <url>%2F2018%2F09%2F28%2Ftheory%2Flinux%2Flinux-cgroup-interface%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;Cgroup,全称Control Group（控制组），用于限制和隔离一组进程对系统资源的调用，即做资源QoS（Quality of Service，服务质量）。&emsp;&emsp;Cgroup的原生接口通过cgroupfs提供，类似于procfs和sysfs，是一种虚拟文件系统。 挂载cgroupfs&emsp;&emsp;此过程一般在启动时由linux发行版做好了。标准挂载点是/sys/fs/cgroup,可以变更。 12345678910111213mount -t cgroup -o cpuset /sys/fs/cgroup/cpuset/# mount: cgroup 已经挂载或 /sys/fs/cgroup/cpuset 忙# cgroup 已经挂载到 /sys/fs/cgroup/systemd 上# cgroup 已经挂载到 /sys/fs/cgroup/blkio 上# cgroup 已经挂载到 /sys/fs/cgroup/freezer 上# cgroup 已经挂载到 /sys/fs/cgroup/devices 上# cgroup 已经挂载到 /sys/fs/cgroup/perf_event 上# cgroup 已经挂载到 /sys/fs/cgroup/net_cls,net_prio 上# cgroup 已经挂载到 /sys/fs/cgroup/cpuset 上# cgroup 已经挂载到 /sys/fs/cgroup/cpu,cpuacct 上# cgroup 已经挂载到 /sys/fs/cgroup/hugetlb 上# cgroup 已经挂载到 /sys/fs/cgroup/pids 上# cgroup 已经挂载到 /sys/fs/cgroup/memory 上 查看cgroupfs&emsp;&emsp;cpuset开头的子文件都是由cpuset子系统产生的，其他文件则由Cgroup产生。这里的tasks文件记录了这个Cgroup的所有进程，包括线程。 123456789101112ls /sys/fs/cgroup/cpuset/# cgroup.clone_children cpuset.memory_pressure# cgroup.event_control cpuset.memory_pressure_enabled# cgroup.procs cpuset.memory_spread_page# cgroup.sane_behavior cpuset.memory_spread_slab# cpuset.cpu_exclusive cpuset.mems# cpuset.cpus cpuset.sched_load_balance# cpuset.effective_cpus cpuset.sched_relax_domain_level# cpuset.effective_mems notify_on_release# cpuset.mem_exclusive release_agent# cpuset.mem_hardwall tasks# cpuset.memory_migrate 创建Cgroup &emsp;&emsp;通过mkdir创建一个新的目录，也就是常见了一个新的Cgroup 1mkdir /sys/fs/cgroup/cpuset/child 配置Cgroup &emsp;&emsp;配置这个Cgroup的资源配额，通过以下命令，可以先哲这个Cgroup的进程只能在0号cpu上运行，并且只能在0号内存节点分配内存。 12echo 0 &gt; /sys/fs/cgroup/cpuset/child/cpuset.cpusecho 0 &gt; /sys/fs/cgroup/cpuset/child/cpuset.mems 使能Cgroup &emsp;&emsp;通过将进程id写进tasks文件，将整个进程移动到Cgroup中，Cgroup真正起作用了 1echo $$ &gt; /sys/fs/cgroup/cpuset/child/tasks # $$表示当前进程id]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cgroup</tag>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker使用记录]]></title>
    <url>%2F2018%2F09%2F28%2Fusing%2Fmiddleware%2Fdocker-using%2F</url>
    <content type="text"><![CDATA[安装1yum install -y docker 修改docker下载源为国内源(这里使用的阿里源)12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; "registry-mirrors": ["https://n9tog3ea.mirror.aliyuncs.com"]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 其他源：Docker 官方中国区 https://registry.docker-cn.com网易 http://hub-mirror.c.163.comustc https://docker.mirrors.ustc.edu.cn Docker镜像使用1234567891011#docekr search software 查找镜像docker search httpd#docker pull software 下拉镜像docker pull redisdocker pull mariadbdocekr pull mongodocker pull cloudesire/activemqdocker pull rabbitmqdocker pull rabbitmq:3-managementdocker pull nginxdocker pull tomcat docker指令帮助12345docker --help#docker command --help 查看docker帮助docker start --help#man docker command 查看command的man文档man docker start]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分赌本问题]]></title>
    <url>%2F2018%2F09%2F27%2Ftheory%2Falgorithm%2Fpoints_bookies%2F</url>
    <content type="text"><![CDATA[问题描述&emsp;&emsp;假设A、B两个人赌博，假设每一局中每人获胜的概率是相同的，刚开始下的赌注均是100法郎，并且约定双方谁先获胜3局，谁就拿走所有的赌本，但是中途由于一些原因，不得不终止比赛，此时A胜2局，B胜1局，问此时赌本该怎么分配才均匀？&emsp;&emsp;注意：假设在赛点不会出现平局。 思路解析 假设继续赌下去，至多两局结束 若接下来的第四局A胜（1/2），则A获得所有赌注 若接下来的第四局B胜（1/2），则进行第五局，第五局中，A胜（1/2*1/2=1/4）才能获得所有赌注 python模拟12345678910111213141516171819202122232425262728293031323334#!/usr/bin/env python3# -*- coding: utf-8 -*-""" @author zhangbohan.dell@gmail.com @function: 分赌本问题 @create 2018/9/27 11:00"""import random''':param n 赢钱所需要的局数:param n1 第一个人已经赢得局数:param n2 第二个人已经赢得局数本程序中取n =3,n1 = 2,n2 = 1'''def Bookies(n, n1, n2): for i in range(2 * n - n1 - n2 - 1): D = random.randint(1, 2) if D == 1: n1 += 1 else: n2 += 1 if n1 == n: return 1 if n2 == n: return 2n = 10000win = 0for i in range(n): if Bookies(3, 2, 1) == 1: win += 1print("A获得赢钱的可能为&#123;&#125;".format(float(win / n)))]]></content>
      <categories>
        <category>probability theory</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>probability theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蒙提霍尔三门问题]]></title>
    <url>%2F2018%2F09%2F27%2Ftheory%2Falgorithm%2Fthree-door%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;蒙提霍尔三门问题亦称蒙提霍尔悖论 问题描述&emsp;&emsp;参赛者会看见三扇关闭了的门，其中一扇的后面有一辆汽车，选中后面有车的那扇门可赢得该汽车，另外两扇门后面则各藏有一只山羊。当参赛者选定了一扇门，但未去开启它的时候，节目主持人开启剩下两扇门的其中一扇，露出其中一只山羊。主持人其后会问参赛者要不要换另一扇仍然关上的门。&emsp;&emsp;问题是：换另一扇门会否增加参赛者赢得汽车的机率？ 思路解析 三扇门，只有一扇门后有有汽车，其余的为山羊 汽车事前等可能放置到三扇门中的其中一个 参赛者等可能选择其中一扇，挑选前不知道门后有什么 主持人清楚的知道门后有什么 如果参赛者挑选了一扇有山羊的门，则主持人必须打开另一扇有山羊的门 如果参赛者挑选了有汽车的门，主持人等可能在另外两扇有山羊的门选择一扇打开 参赛者会被问保持原先选择还是转而选择另一扇门 Python模拟以上过程123456789101112131415161718192021222324252627282930313233343536373839#!/usr/bin/env python3# -*- coding: utf-8 -*-""" @author zhangbohan.dell@gmail.com @function: 蒙提霍尔三门问题 @create 2018/9/27 10:09"""import randomdef MontyHall(Dselect, Dchange): Dcar = random.randint(1, 3) # 随机等可能放置汽车 if Dcar == Dselect and Dchange == 0: # 一开始选中并且没有改变选择 return 1 elif Dcar != Dselect and Dchange == 0: # 一开始没选中也没有改变选择 return 0 elif Dcar == Dselect and Dchange == 1: # 一开始选中并且改变选择 return 0 else: # 一开始没选中并且改变选择 return 1n = 10000win = 0for i in range(n): select = random.randint(1, 3) win += MontyHall(select, random.randint(0, 1))print("不确认是够改变选择&#123;&#125;".format(float(win / n)))win = 0for i in range(n): select = random.randint(1, 3) win += MontyHall(select, 0)print("确认不改变选择&#123;&#125;".format(float(win / n)))win = 0for i in range(n): select = random.randint(1, 3) win += MontyHall(select, 1)print("确认改变选择&#123;&#125;".format(float(win / n)))]]></content>
      <categories>
        <category>probability theory</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>probability theory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos使用记录]]></title>
    <url>%2F2018%2F09%2F26%2Fusing%2Flinux%2Fcentos-using%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;个人喜欢使用CentOS7 系统，本帖记录使用CentOS所使用的过程，安装过程 略 （我习惯采用最小化安装） 安装图形化界面123yum groupinstall "GNOME Desktop" "Graphical Administration Tools" #安装GNOME图形化界面(时间较长，耐心等待)ln -sf /lib/systemd/system/runlevel5.target /etc/systemd/system/default.target #设置图形化界面为默认启动选项reboot # 重启CentOS 启动网络连接（手动配置网卡信息）&emsp;&emsp;安装过程没选择网络或者网卡没有自动连接,或者修改网卡配置（比如修改为固定ip等等） 123ip addr #查看你的网卡信息cat /etc/sysconfig/network-scripts/ifcfg-ens33 #打印查看网卡信息vi /etc/sysconfig/network-scripts/ifcfg-ens33 #修改网卡信息如下 123456789101112131415TYPE=EthernetPROXY_METHOD=noneBROWSER_ONLY=noBOOTPROTO=dhcpDEFROUTE=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyNAME=ens33UUID=a6bf4243-3908-4096-a87d-aabc853fffbaDEVICE=ens33ONBOOT=yes #修改的地方，改no为yes ，自动启动 安装网络工具包1yum install -y net-tools #包含ifconfig等命令 修改yum安装源为阿里源1234567 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo_bak #备份原有源信息wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo #下载阿里源到本地yum makecache #建立缓存yum -y update #对现有安装程序升级 安装中文输入法1yum install -y ibus ibus-libpinyin 设置 -&gt; 区域和语言 -&gt; 输入源 -&gt; 新加 -&gt; 汉语（中国） -&gt; 汉语（intelligent Pinyin） 安装jdk12345678rpm -qa | grep java #查找已经安装的jdkrpm -e --nodeps java-1.7.0-openjdk # 卸载掉rpm -e --nodeps java-1.8.0-openjdk # 卸载掉rpm -e --nodeps java-1.8.0-openjdk-headless # 卸载掉rpm -e --nodeps java-1.7.0-openjdk-headless # 卸载掉rpm -ivh jdk-8u181-linux-x64.rpm # 安装下载好的rpmvim /etc/profile # 添加jdk到环境变量如下source /etc/profile #是环境变量有效 12345#/etc/profile 末尾添加一下内容#java environmentexport JAVA_HOME=/usr/java/jdk1.8.0_181-amd64export CLASSPATH=.:$&#123;JAVA_HOME&#125;/jre/lib/rt.jar:$&#123;JAVA_HOME&#125;/lib/dt.jar:$&#123;JAVA_HOME&#125;/lib/tools.jarexport PATH=$PATH:$&#123;JAVA_HOME&#125;/bin 安装hadoop123456#已经安装并且配置jdkcd /opt/hadoop # 切换目录wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.9.0/hadoop-2.9.0.tar.gz #下载hadooptar -zxvf hadoop-2.9.0.tar.gz # 解压cd hadoop-2.9.0 # 进入hadoop目录./bin/hadoop version # 查看hadoop是否能使用 安装redis以及基础配置12yum install epel-release -y # 下载fedora的epel仓库yum install -y redis # 安装redis redis配置信息 123456# file &gt;&gt; /etc/redis.conf### 添加密码requirepass yourpassword ### redis远程连接#bind 127.0.0.1 添加注释protected-mode no]]></content>
      <categories>
        <category>CentOS7</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>CentOS7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot-mail]]></title>
    <url>%2F2018%2F09%2F20%2Fusing%2Fjava%2Fframework%2Fspringboot-mail%2F</url>
    <content type="text"><![CDATA[&emsp;&emsp;配置springboot发送简易右键 maven依赖123456&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 编写service以及实现123456789101112131415161718192021222324252627282930//Servicepublic interface MailService &#123; void sendSimpleMail(String to, String subject, String content);&#125;//ServiceImpl@Component@Logpublic class MailServiceImpl implements MailService &#123; @Resource private JavaMailSender javaMailSender; @Value("$&#123;mail.fromMail.addr&#125;") private String from; @Override public void sendSimpleMail(String to, String subject, String content) &#123; SimpleMailMessage message = new SimpleMailMessage(); message.setFrom(from); message.setTo(to); message.setSubject(subject); message.setText(content); try &#123; javaMailSender.send(message); log.info("简单邮件已经发送。"); &#125; catch (Exception e) &#123; log.info("发送简单邮件时发生异常！"+e); &#125; &#125;&#125; 配置必要属性设置123456789spring: mail: host: smtp.qq.com username: xzx@qq.com default-encoding: UTF-8 password: passwordmail: fromMail: addr: xzx@qq.com 测试1234567891011121314@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = WebsiteApplication.class)@WebAppConfigurationpublic class MailServiceTest &#123; @Resource private MailService mailServiceImpl; @Test public void testSimpleMail() throws Exception &#123; mailServiceImpl.sendSimpleMail("mir2285@outlook.com", "test simple mail", " hello this is simple mail"); &#125;&#125;]]></content>
      <categories>
        <category>springboot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
        <tag>email</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python多线程]]></title>
    <url>%2F2018%2F09%2F19%2Fusing%2Fpython%2Fbasic%2Fpython-thread%2F</url>
    <content type="text"><![CDATA[Python中的多线程GIL全局解释器锁&emsp;&emsp;线程的执行权限。Python的进程中只有一个GIL，一个线程需要执行任务，就必须要获取GIL &emsp;好处&emsp;&emsp;直接杜绝了多线程下访问内存空间的安全问题 &emsp;缺陷&emsp;&emsp;Python多线程并非真正多线程，不能充分利用多核cpu的资源，在i/o阻塞时候，解释器会释放GIL 多线程&emsp;&emsp;密集I/O任务（网络I/O，磁盘I/O，数据库I/O）使用多线程合适 &emsp; 缺陷&emsp;&emsp;同一时间切片只能运行一个程序，不能做到高并行，但可以做到高并发 协程&emsp;&emsp;又称微线程，在单线程上执行多个任务，用函数切换，开销极小，不通过操作系统调度，无线程、进程切换开销 &emsp; 与线程区别&emsp;&emsp;多线程请求返回无序，那个线程有数据返回就处理那个；而协程返回的数据是有顺序的 缺陷&emsp;&emsp;单线程执行，处理密集CPU和本地磁盘I/O时，性能较低，处理网络I/O，性能还较好 &emsp;&emsp;理论上来说，线程、协程在I/O密集的操作时性能高于进程]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构 - 树]]></title>
    <url>%2F2018%2F09%2F17%2Ftheory%2Falgorithm%2Falgorithm-tree%2F</url>
    <content type="text"><![CDATA[树&emsp;&emsp; 一棵树是一些节点的集合。如果这棵树非空，则一棵树由称作根（root）节点的r以及0个或者多个非空的(子)树组成，这些子树中每一棵的根都被来自根r的一条有向的边（edge）所连接。&emsp;&emsp;每一棵子树的根叫做r的儿子，r是每一棵子树的根的父亲。没有儿子的节点称为树叶，具有相同父节点的节点称为兄弟。]]></content>
      <categories>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>algorithm</tag>
        <tag>data structure</tag>
        <tag>tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyQt学习记录（一） -- 初识PyQt]]></title>
    <url>%2F2018%2F09%2F11%2Fusing%2Fpython%2Fframework%2Fpyqt-1%2F</url>
    <content type="text"><![CDATA[PyQt介绍&emsp;&emsp;PyQt5是一套Python绑定Digia QT5应用的框架。它可用于Python 2和3。本教程使用Python 3。Qt库是最强大的GUI库之一。PyQt5的官方网站http://www.riverbankcomputing.co.uk/news。&emsp;&emsp;PyQt5做为Python的一个模块，它有620多个类和6000个函数和方法。这是一个跨平台的工具包，它可以运行在所有主要的操作系统，包括UNIX，Windows，Mac OS。PyQt5是双重许可。开发者可以在GPL和商业许可之间进行选择。、 PyQt模块 QtCore:包含了核心的非GUI功能。此模块用于处理时间、文件和目录、各种数据类型、流、URL、MIME类型、线程或进程。 QtGui包含类窗口系统集成、事件处理、二维图形、基本成像、字体和文本。 qtwidgets模块包含创造经典桌面风格的用户界面提供了一套UI元素的类。 QtMultimedia包含的类来处理多媒体内容和API来访问相机和收音机的功能。 Qtbluetooth模块包含类的扫描设备和连接并与他们互动。描述模块包含了网络编程的类。这些类便于TCP和IP和UDP客户端和服务器的编码，使网络编程更容易和更便携。 Qtpositioning包含类的利用各种可能的来源，确定位置，包括卫星、Wi-Fi、或一个文本文件。 Enginio模块实现了客户端库访问Qt云服务托管的应用程序运行时。 Qtwebsockets模块包含实现WebSocket协议类。 QtWebKit包含一个基于Webkit2图书馆Web浏览器实现类。 Qtwebkitwidgets包含的类的基础webkit1一用于qtwidgets应用Web浏览器的实现。 QtXml包含与XML文件的类。这个模块为SAX和DOM API提供了实现。 QtSvg模块提供了显示SVG文件内容的类。可伸缩矢量图形（SVG）是一种描述二维图形和图形应用的语言。 QtSql模块提供操作数据库的类。 QtTest包含的功能，使PyQt5应用程序的单元测试 PyQt5尝试1234567891011121314151617181920212223242526272829# -*- coding: utf-8 -*- """PyQt5 学习""" import sys #这里我们提供必要的引用。基本控件位于PyQt5.qtwidgets模块中。from PyQt5.QtWidgets import QApplication, QWidget if __name__ == '__main__': #每一PyQt5应用程序必须创建一个应用程序对象。sys.argv参数是一个列表，从命令行输入参数。 app = QApplication(sys.argv) #QWidget部件是PyQt5所有用户界面对象的基类。他为QWidget提供默认构造函数。默认构造函数没有父类。 w = QWidget() #resize()方法调整窗口的大小。这离是250px宽150px高 w.resize(250, 150) #move()方法移动窗口在屏幕上的位置到x = 300，y = 300坐标。 w.move(300, 300) #设置窗口的标题 w.setWindowTitle('Simple') #显示在屏幕上 w.show() #系统exit()方法确保应用程序干净的退出 #的exec_()方法有下划线。因为执行是一个Python关键词。因此，exec_()代替 sys.exit(app.exec_()) 效果如图： 参考资料https://maicss.gitbooks.io/PyQt5/content/Python Qt GUI 快速编程 —— PyQt编程指南（Mark Summerfield 著 ）]]></content>
      <categories>
        <category>PyQt</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>PyQt</tag>
        <tag>GUI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyQT学习记录（二）]]></title>
    <url>%2F2018%2F09%2F11%2Fusing%2Fpython%2Fframework%2Fpyqt-2%2F</url>
    <content type="text"><![CDATA[PyQt5 程序基础解析1234import sysimport time from PyQt5.QtCore import *from PyQt5.QtGui import * 导入sys模块，为了访问在sys.argv列cd cd 表中的那些命令行参数 导入time模块，使用time.sleep() 1app = QApplication(sys.argv) &emsp;&emsp;每个PyQt GUI程序都必须有一个QApplication对象。这个对象会提供访问全局信息的能力，包括程序的目录、屏幕大小、程序运行在哪个屏幕上（对于多线程系统来说）。这个对象还还会提供后续会说到的事件循环。&emsp;&emsp;PyQt可以是是被一些自己的参数的，如 - geometry 和 - style 等，这些参数在QApplication的初始化文档中。 &emsp;&emsp;调用app.exec_()会开始执行QApplication对象的事件循环，第一个事件就是绘制事件，调用QApplication.quit()方法会干净的结束该GUI程序，关闭所有已经打开的窗口，释放所占用的资源，然后退出程序。&emsp;&emsp;事件循环用伪代码展示就是这个样子：123456while True: event = getNextEvent() if event: if event == Terminates: break processEvent(Event) &emsp;&emsp;当用户与应用程序交互的时候，或是发生特定事情时，会在PyQt内部产生一个事件并将其添加到事件列表中去。 PyQt5布局1. 绝对定位&emsp;&emsp;程序指定每个控件的位置和大小(以像素为单位)。绝对定位有以下限制:&emsp;- 如果我们调整窗口，控件的大小和位置不会改变&emsp;- 在各种平台上应用程序看起来会不一样&emsp;- 如果改变字体，我们的应用程序的布局就会改变&emsp;- 如果我们决定改变我们的布局,我们必须完全重做我们的布局 2. 盒布局 Boxlayout&emsp;&emsp;我们使用QHBoxLayout和QVBoxLayout，来分别创建横向布局和纵向布局&emsp;&emsp;如果我们需要把两个按钮放在程序的右下角，创建这样的布局，我们只需要一个水平布局加一个垂直布局的盒子就可以了。再用弹性布局增加一点间隙。 3. 格栅布局&emsp;&emsp;最常用的还是栅格布局了。这种布局是把窗口分为行和列。创建和使用栅格布局，需要使用QGridLayout模块。 做了一个小型的demo关于pyqt的更多知识，有空余时间的时候会继续补充。项目地址： ncmdump项目介绍： 原作者写出了ncm转换为MP3的基础版本，用这不是很方便，就用正在学习的pyrt做了一个初版的demo图形化界面，后续有时间继续优化]]></content>
      <categories>
        <category>PyQT</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>GUI</tag>
        <tag>PyQT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的使用（二）-- 详细了解Nginx]]></title>
    <url>%2F2018%2F09%2F01%2Fusing%2Fmiddleware%2Fnginx-2%2F</url>
    <content type="text"><![CDATA[为什么使用Nginx 更快&emsp;&emsp;主要表现在两个方面：1，正常情况下，单次请求会得到更快的响应；2，在高峰期（数以万计的并发请求），Nginx可以比其他web服务器更快地请求响应。 高扩展性&emsp;&emsp;它完全是由多个不同功能、 不同层次、 不同类型且耦合度低的模块组成。 高可靠性 &emsp;&emsp;Nginx 的高可靠性来自于其核心框架代码的优秀设计、 模块设计的简单性。每个 worker进程相对独立， master 进程在 1 个 worker 进程出错时可以快速“拉起”新的 worker 子进程提供服务。 低内存消耗 &emsp;&emsp;一般情况下， 10 000 个非活跃的 HTTP Keep-Alive 连接在 Nginx 中仅消耗 2.5MB 的内存， 这是 Nginx 支持高并发连接的基础。 单机支持 10 万以上的并发连接 热部署 &emsp;&emsp;可以在 7×24 小时不间断服务的前提下， 升级 Nginx 的可执行文件。 当然， 它也支持不停止服务就更新配置项、 更换日志文件等功能。 最自由的BSD许可协议 &emsp;&emsp;允许用户在自己的项目中直接使用或修改 Nginx 源码。 使用Nginx的必备软件 GCC编译器&emsp;&emsp;用来编译nginx的各个模块 PCRE库&emsp;&emsp;PCRE（Perl Compatible Regular Expressions， Perl 兼容正则表达式） 是由 Philip Hazel开发的函数库， 目前为很多软件所使用， 该库支持正则表达式。当然，如果不打算在nginx中使用正则表达式，那么这个就不是必需的。 zlib库 &emsp;&emsp;zlib 库用于对 HTTP 包的内容做 gzip 格式的压缩， 如果我们在 nginx.conf 里配置了 gzip on， 并指定对于某些类型（content-type） 的 HTTP 响应使用 gzip 来进行压缩以减少网络传， 那么， 在编译时就必须把 zlib 编译进 Nginx。 OpenSSL 开发库&emsp;&emsp;在SSL 协议上传输 HTTP，以及使用MD5、 SHA1 等散列函数都需要OpenSSL 开发库的支持。运行中的Nginx进程间的关系 &emsp;&emsp;部署 Nginx 时都是使用一个 master 进程来管理多个worker 进程， 一般情况下， worker 进程的数量与服务器上的 CPU 核心数相等。 Nginx文件路径的常用定义 以 root 方式设置资源路径语法： root path;默认： root html;配置块： http、 server、 location、 if&emsp;&emsp;例如， 定义资源文件相对于 HTTP 请求的根目录。 123location /download/ &#123; root /opt/web/html/;&#125; &emsp;&emsp;在上面的配置中， 如果有一个请求的 URI 是 /download/index/test.html， 那么 Web 服务器将会返回服务器上 /opt/web/html/download/index/test.html 文件的内容。 以 alias 方式设置资源路径语法： alias path;配置块： location&emsp;&emsp;alias 也是用来设置文件资源路径的， 它与 root 的不同点主要在于如何解读紧跟 location后面的 uri 参数， 这将会致使 alias 与 root 以不同的方式将用户请求映射到真正的磁盘文件上。 例如， 如果有一个请求的 URI 是 /conf/nginx.conf， 而用户实际想访问的文件在 /usr/local/nginx/conf/nginx.conf， 那么想要使用 alias 来进行设置的话， 可以采用如下方式： 123location /conf &#123;alias /usr/local/nginx/conf/;&#125; 如果用 root 设置， 那么语句如下所示： 123location /conf &#123;root /usr/local/nginx/;&#125; alias 后面还可以添加正则表达式， 例如： 123location ~ ^/test/(\w+)\.(\w+)$ &#123;alias /usr/local/nginx/$2/$1.$2;&#125; &emsp;&emsp;这样， 请求在访问 /test/nginx.conf 时， Nginx 会返回 /usr/local/nginx/conf/nginx.conf 文件中的内容。 访问首页语法： index file …;默认： index index.html;配置块： http、 server、 location&emsp;&emsp;有时， 访问站点时的 URI 是 /， 这时一般是返回网站的首页， 而这与 root 和 alias 都不同。 这里用 ngx_http_index_module 模块提供的 index 配置实现。 index 后可以跟多个文件参数， Nginx 将会按照顺序来访问这些文件， 例如： 1234location / &#123;root path;index /index.html /html/index.php /index.php;&#125;]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mycat使用记录一 -- 安装与配置]]></title>
    <url>%2F2018%2F08%2F30%2Fusing%2Fmiddleware%2Fmycat-1%2F</url>
    <content type="text"><![CDATA[rkdownm 背景条件&emsp;&emsp;现有app流量数据统计分析系统，因数据量过大使用单数据库性能有限，打算将现有数据库进行优化，计划使用mycat实现分布式，在本地搭建环境学习 环境&emsp;&emsp;VMware虚拟机下的Cetnos7 × 3台 mycat的安装 下载mycat，这里我选择的是1.6.5版本，也就是目前的release版本。 上传至linux系统，解压至/opt/mycat(我习惯的目录) mycat的配置配置文件路径$mycat_home$指的是安装目录$mycat_home$/conf/server.xml Mycat的配置文件，设置账号、参数等$mycat_home$/conf/schema.xml Mycat对应的物理数据库和数据库表的配置$mycat_home$/conf/rule.xml Mycat分片（分库分表）规则 具体配置 wrapper.conf—配置jdk(如果已经配置java环境变量，这一步可以忽略) 12wrapper.java.command=/usr/bin/java#配置java的路径 server.xml user标签 12345&lt;user name="root" defaultAccount="true"&gt;&lt;property name="password"&gt;your_password&lt;/property&gt;&lt;property name="schemas"&gt;db1,db2&lt;/property&gt;&lt;property name="readOnly"&gt;false&lt;/property&gt;&lt;/user&gt; user 用户配置节点—name 登录的用户名，也就是连接Mycat的用户名—password 登录的密码，也就是连接Mycat的密码—schemas 数据库名，这里会和schema.xml中的配置关联，多个用逗号分开，例如需要这个用户需要管理两个数据库db1,db2，则配置db1,dbs privileges标签 123456789 &lt;privileges check="false"&gt; 默认关闭 &lt;schema name="TESTDB" dml="0110" &gt; &lt;table name="tb 01" dml="0000"&gt;&lt;/table&gt; &lt;table name="tb02" dml="1111"&gt;&lt;/table&gt; 1 代表有权限 0 代表无权限 顺序为 insert,update,select,delete &lt;/schema&gt;&lt;/privileges&gt; system标签&emsp;&emsp;这个标签内嵌套的所有 property 标签都与系统配置有关。 firewall标签&emsp;&emsp;有关防火墙的标签，也就是在网络层对请求的地址进行限制，主要是从安全角度来保证Mycat不被匿名IP进行访问 123456789101112131415 &lt;!-- 全局SQL防火墙设置 --&gt; &lt;!--白名单可以使用通配符%或着*--&gt; &lt;!--例如&lt;host host="127.0.0.*" user="root"/&gt;--&gt; &lt;!--例如&lt;host host="127.0.*" user="root"/&gt;--&gt; &lt;!--例如&lt;host host="127.*" user="root"/&gt;--&gt; &lt;!--例如&lt;host host="1*7.*" user="root"/&gt;--&gt; &lt;!--这些配置情况下对于127.0.0.1都能以root账户登录--&gt; &lt;!-- &lt;firewall&gt; &lt;whitehost&gt; &lt;host host="1*7.0.0.*" user="root"/&gt; &lt;/whitehost&gt; &lt;blacklist check="false"&gt; &lt;/blacklist&gt;&lt;/firewall&gt; schema.xml— schema 数据库设置，此数据库为逻辑数据库，name与server.xml中schema对应— dataNode 分片信息，也就是分库相关配置— dataHost 物理数据库，真正存储数据的数据库 schema标签&emsp;&emsp;schema标签用来定义mycat实例中的逻辑库，mycat可以有多个逻辑库，每个逻辑库都有自己的相关配置。可以使用schema标签来划分这些不同的逻辑库&emsp;&emsp;如果不配置schema标签，所有表的配置会属于同一个默认的逻辑库。逻辑库的概念和MySql的database的概念一样，我们在查询两个不同逻辑库中的表的时候，需要切换到该逻辑库下进行查询。 1234567&lt;schema name=" " checkSQLschema="false" sqlMaxLimit="100"&gt;&lt;/schema&gt;&lt;!--name 逻辑数据库名,与server.xml中的schema对应checkSQLschema 数据库前缀相关设置，当该值为true时，例如我们执行语句select * from TESTDB.company 。mycat会把语句修改为 select * from company 去掉TESTDB。sqlMaxLimit 当该值设置为某个数值时，每条执行的sql语句，如果没有加上limit语句，Mycat会自动加上对应的值。不写的话，默认返回所有的值。--&gt; table标签—name 表名，物理数据库中表名—dataNode 表存储到哪些节点，多个节点用逗号分隔。节点为下文dataNode设置的name—primaryKey主键字段名，自动生成主键时需要设置—autoIncrement 是否自增—rule 分片规则名，具体规则下文rule详细介绍—type 该属性定义了逻辑表的类型，目前逻辑表只有全局表和普通表。全局表： global 普通表：无&emsp;&emsp;注：全局表查询任意节点，普通表查询所有节点效率低—autoIncrement mysql对非自增长主键，使用last_insert_id() 是不会返回结果的，只会返回0。所以，只有定义了自增长主键的表，才可以用last_insert_id()返回主键值。mycat提供了自增长主键功能，但是对应的mysql节点上数据表，没有auto_increment,那么在mycat层调用last_insert_id()也是不会返回结果的。—needAddLimit 指定表是否需要自动的在每个语句后面加上limit限制，由于使用了分库分表，数据量有时候会特别庞大，这时候执行查询语句，忘记加上limt就会等好久，所以mycat自动为我们加上了limit 100，这个属性默认为true，可以自己设置为false禁用。如果使用这个功能，最好配合使用数据库模式的全局序列。—subTables 分表，分表目前不支持Join。 123&lt;table name=“test” primaryKey="ID" autoIncrement="true" dataNode=“dn1,dn2,dn3” /&gt;&lt;table name=“mine” primaryKey="ID" autoIncrement="true" dataNode=“dn1,dn2,dn3” /&gt;&lt;table name=“new” primaryKey="ID" autoIncrement="true" dataNode=“dn1,dn2,dn3” /&gt; childTable标签—childTable 标签用于定义 E-R 分片的子表。通过标签上的属性与父表进行关联。—name 子表的名称—joinKey 子表中字段的名称—parentKey 父表中字段名称—primaryKey 同Table—needAddLimit 同Table 123&lt;table name="customer" primaryKey="ID" dataNode="dn1,dn2" rule="sharding-by-intfile"&gt;&lt;childTable name="c_a" primaryKey="ID" joinKey="customer_id" parentKey="id" /&gt;&lt;/table&gt; dataNode标签&emsp;&emsp;datanode标签定义了mycat中的数据节点，也就是我们所说的数据分片。一个datanode标签就是一个独立的数据分片。&emsp;&emsp;例子中的表述的意思为，使用名字为localhost1数据库实例上的db1物理数据库，这就组成一个数据分片，最后我们用dn1来标示这个分片。—name 定义数据节点的名字，这个名字需要唯一。我们在table标签上用这个名字来建立表与分片对应的关系—dataHost 用于定义该分片属于哪个数据库实例，属性与datahost标签上定义的name对应—database 用于定义该分片属于数据库实例上 的具体库。 1&lt;dataNode name="dn1" dataHost="localhost1" database="db1" /&gt; dataHost标签—name 唯一标示dataHost标签，供上层使用—maxCon 指定每个读写实例连接池的最大连接。—minCon 指定每个读写实例连接池的最小连接，初始化连接池的大小—balance 负载均称类型&emsp;&emsp;balance=”0”：不开启读写分离机制，所有读操作都发送到当前可用的writeHost上&emsp;&emsp;balance=”1”：全部的readHost与stand by writeHost参与select语句的负载均衡，简单的说，当双主双从模式（M1-S1，M2-S2 并且M1 M2互为主备），正常情况下，M2,S1,S2都参与select语句的负载均衡。&emsp;&emsp;balance=”2”：所有读操作都随机的在writeHost、readHost上分发&emsp;&emsp;balance=”3”：所有读请求随机的分发到writeHst对应的readHost执行，writeHost不负担读写压力。（1.4之后版本有）—writeType 负载均衡类型。&emsp;&emsp;writeType=”0”, 所有写操作发送到配置的第一个 writeHost，第一个挂了切到还生存的第二个writeHost，重新启动后已切换后的为准，切换记录在配置文件中:dnindex.properties .&emsp;&emsp;writeType=”1”，所有写操作都随机的发送到配置的 writeHost。1.5以后版本废弃不推荐。—switchType&emsp;&emsp;-1 不自动切换&emsp;&emsp;1 默认值 自动切换&emsp;&emsp;2 基于MySql主从同步的状态决定是否切换，心跳语句为 show slave status&emsp;&emsp;3 基于 MySQL galary cluster 的切换机制（适合集群）（1.4.1）,心跳语句为 show status like ‘wsrep%’—dbType 指定后端链接的数据库类型目前支持二进制的mysql协议，还有其他使用jdbc链接的数据库，例如：mongodb，oracle，spark等—dbDriver 指定连接后段数据库使用的driver，目前可选的值有native和JDBC。使用native的话，因为这个值执行的是二进制的mysql协议，所以可以使用mysql和mariadb，其他类型的则需要使用JDBC驱动来支持。1.6版本开始支持postgresql的原始协议。如果使用JDBC的话需要符合JDBC4标准的驱动jar 放到mycat\lib目录下，并检查驱动jar包中包括如下目录结构文件 META-INF\services\java.sql.Driver。 在这个文件写上具体的driver类名，例如com.mysql.jdbc.Driver—tempReadHostAvailable&emsp;&emsp;如果配置了这个属性 writeHost 下面的 readHost 仍旧可用，默认 0 可配置（0、1）。 123456&lt;dataHost name="localhost1" maxCon="1000" minCon="10" balance="0" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host="hostM1" url="192.168.1.100:3306" user="root" password="123456"&gt; &lt;readHost host="hostS1" url="192.168.1.101:3306" user="root" password="123456" /&gt; &lt;/writeHost&gt;&lt;/dataHost&gt; heartbeat标签&emsp;&emsp;这个标签内指明用于和后端数据库进行心跳检查的语句。例如：MYSQL 可以使用 select user()，Oracle 可以使用 select 1 from dual 等。&emsp;&emsp;这个标签还有一个 connectionInitSql 属性，主要是当使用 Oracla 数据库时，需要执行的初始化 SQL 语句就放到这里面来。例如：alter session set nls_date_format=’yyyy-mm-dd hh24:mi:ss ‘1.4 主从切换的语句必须是：show slave status writeHost /readHost 标签&emsp;&emsp;这两个标签都指定后端数据库的相关配置，用于实例化后端连接池。唯一不同的是，writeHost 指定写实例、readHost 指定读实例。&emsp;&emsp;在一个 dataHost 内可以定义多个 writeHost 和 readHost。但是，如果 writeHost 指定的后端数据库宕机，那么这个 writeHost 绑定的所有 readHost 都将不可用。&emsp;&emsp;另一方面，由于这个 writeHost 宕机，系统会自动的检测到，并切换到备用的 writeHost 上去。这两个标签的属性相同，这里就一起介绍。—host 用于标识不同实例，一般 writeHost 我们使用M1，readHost我们用S1。—url 后端实例连接地址。Native：地址：端口 JDBC：jdbc的url—password 后端存储实例需要的密码—user 后端存储实例需要的用户名字—weight 权重 配置在 readhost 中作为读节点的权重—usingDecrypt 是否对密码加密，默认0。具体加密方法看官方文档。]]></content>
      <categories>
        <category>middleware</category>
      </categories>
      <tags>
        <tag>middleware</tag>
        <tag>linux</tag>
        <tag>mycat</tag>
        <tag>db</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux指令记录合集（长期更新）]]></title>
    <url>%2F2018%2F08%2F30%2Fusing%2Flinux%2Flinux-command%2F</url>
    <content type="text"><![CDATA[此命令合集适合于Centos 7 systemctl服务相关指令1234567systemctl start service-name #启动某服务systemctl stop service-name #停止某服务systemctl restart service-name #重启某服务systemctl enable service-name #设置开机自动启动某服务systemctl disable service-name #设置开机停止自动启动某服务systemctl list-units --type=service #查看所有已启动的服务systemctl list-unit-files #查看已经安装的所有服务 添加程序到服务systemctl脚本存放在:/usr/lib/systemd/&emsp;&emsp;[Unit]部分主要是对这个服务的说明，内容包括Description和After，Description 用于描述服务，After用于描述服务类别&emsp;&emsp;[Service]部分是服务的关键，是服务的一些具体运行参数的设置.&emsp;&emsp;Type=forking是后台运行的形式，&emsp;&emsp;User=users是设置服务运行的用户,&emsp;&emsp;Group=users是设置服务运行的用户组,&emsp;&emsp;PIDFile为存放PID的文件路径，&emsp;&emsp;ExecStart为服务的具体运行命令,&emsp;&emsp;ExecReload为重启命令，&emsp;&emsp;ExecStop为停止命令，&emsp;&emsp;PrivateTmp=True表示给服务分配独立的临时空间 注意：[Service]部分的启动、重启、停止命令全部要求使用绝对路径，使用相对路径则会报错！ [Install]部分是服务安装的相关设置，可设置为多用户的 12345678910111213141516171819#以tomcat为例#vim /usr/lib/systemd/system/tomcat.service[Unit]Description=java tomcat projectAfter=tomcat.service [Service]Type=forkingUser=usersGroup=usersPIDFile=/usr/local/tomcat/tomcat.pidExecStart=/usr/local/tomcat/bin/startup.shExecReload=ExecStop=/usr/local/tomcat/bin/shutdown.shPrivateTmp=true [Install]WantedBy=multi-user.target firewall-cmd防火墙相关 12firewall-cmd --add-port=port-number/protocols --zone=zone-name --permanent #在zone-name区域永久开启protocol协议的port-number端口firewall-cmd --zone=public --list-all # 显示所有公共区域（public） ln1ln -s source link #创建一个指向source的link（快捷方式） 后台运行命令 &amp; &emsp;&emsp;当在前台运行某个作业时，终端被该作业占据；可以在命令后面加上&amp; 实现后台运行。例如：sh test.sh &amp; 适合在后台运行的命令有f i n d、费时的排序及一些s h e l l脚本。在后台运行作业时要当心：需要用户交互的命令不要放在后台执行，因为这样你的机器就会在那里傻等。不过，作业在后台运行一样会将结果输出到屏幕上，干扰你的工作。如果放在后台运行的作业会产生大量的输出，最好使用下面的方法把它的输出重定向到某个文件中： 1command &gt; out.file 2&gt;&amp;1 &amp; #所有的标准输出和错误输出都将被重定向到一个叫做out.file 的文件中。 2&gt;&amp;1解析 &emsp;&emsp;2&gt;&amp;1 是将标准出错重定向到标准输出，这里的标准输出已经重定向到了out.file文件，即将标准出错也输出到out.file文件中。最后一个&amp;， 是让该命令在后台执行。 &emsp;&emsp;试想2&gt;1代表什么，2与&gt;结合代表错误重定向，而1则代表错误重定向到一个文件1，而不代表标准输出；换成2&gt;&amp;1，&amp;与1结合就代表标准输出了，就变成错误重定向到标准输出. nohup &emsp;&emsp;使用&amp;命令后，作业被提交到后台运行，当前控制台没有被占用，但是一但把当前控制台关掉(退出帐户时)，作业就会停止运行。nohup命令可以在你退出帐户之后继续运行相应的进程。nohup就是不挂起的意思( no hang up)。该命令的一般形式为： 123nohup command &amp; #在缺省情况下该作业的所有输出都被重定向到一个名为nohup.out的文件中，除非另外指定了输出文件：nohup command &gt; myout.file 2&gt;&amp;1 &amp;nohup command &gt; myout.file 2&gt;&amp;1 &amp; echo $! &gt; pid #将pid号存储到文件中 ctrl + z &emsp;&emsp;可以将一个正在前台执行的命令放到后台，并且处于暂停状态。 jobs &emsp;&emsp;查看当前有多少在后台运行的命令。 1jobs -l #可显示所有任务的PID，jobs的状态可以是running, stopped, Terminated。但是如果任务被终止了（kill），shell 从当前的shell环境已知的列表中删除任务的进程标识。 硬件信息查看123cat /proc/cpuinfo |grep "physical id"|sort|uniq|wc -l #查看物理cpu个数cat /proc/cpuinfo |grep "cpu cores"|wc -l #查看每个物理cpu中的core个数cat /proc/cpuinfo |grep "processor"|wc -l #逻辑cpu的个数 性能信息查看12top #性能监控程序free -m #查看内存使用情况 保存程序运行pid到文件1234567##通过命令行启动进程，然后通过ps ,grep, awk 关键字获取对应pidps -ef|grep s |grep -v grep |awk '&#123;print $2&#125;' &gt; process.PIDFile###如果是使用nohup创建，查看当前shell最后一个后台进程pid $!##注意，下面的命令要放到sh文件里面执行，不能从命令行执行**nohup command &amp; echo $! &gt; process.pid# 既写入文件又输出到标准输出nohup command &amp; echo $!|tee process.pid 修改开机启动模式12systemctl set-default graphical.target #由命令行模式更改为图形界面模式systemctl set-default multi-user.target #由图形界面模式更改为命令行模式 解压tar.gztar命令说明：&emsp;&emsp;语法：tar [主选项+辅选项] 文件或目录&emsp;&emsp;使用该命令时，主选项必须有，它告诉tar要做什么事情，辅选项是辅助使用的，可以选用。主选项：【一条命令以下5个参数只能有一个】&emsp;&emsp;-c: —create 新建一个压缩文档，即打包&emsp;&emsp;-x: —extract,—get解压文件&emsp;&emsp;-t: —list,查看压缩文档里的所有内容&emsp;&emsp;-r:—append 向压缩文档里追加文件&emsp;&emsp;-u:—update 更新原压缩包中的文件辅助选项：&emsp;&emsp;-z:是否同时具有gzip的属性？即是否需要用gzip压缩或解压？一般格式为x.tar.gz或xx.tgz&emsp;&emsp;-j：是否同时具有bzip2的属性？即是否需要用bzip2压缩或解压？一般格式为x.tar.bz2&emsp;&emsp;-v:显示操作过程！这个参数很常用&emsp;&emsp;-f：使用文档名，注意，在f之后要立即接文档名，不要再加其他参数！&emsp;&emsp;-C:切换到指定目录&emsp;&emsp;—exclude FILE:在压缩过程中，不要将FILE打包 1tar -zxvf xxx.tar.gz -C path 配置环境变量12vim /etc/profile #修改环境变量文件内容 export xx_home=pathsource /etc/profile #使环境变量生效]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>command</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lombok使用方法记录]]></title>
    <url>%2F2018%2F08%2F28%2Fusing%2Fjava%2Ftools%2Flombok%2F</url>
    <content type="text"><![CDATA[maven引入jar包12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.20&lt;/version&gt;&lt;/dependency&gt; 给IDE安装插件&emsp;&emsp;由于 Lombok 采取的注解形式的，在编译后，自动生成相应的方法，为了不让 IDE’疯了’，需要下载插件了支持它.&emsp;&emsp;以 idea 为例：查找插件 lombok plugin 安装即可。 一般注解 注解代码 用法 @Getter get方法 @Setter set方法 @ToString ToString方法 @EqualsAndHashCode equals方法和hashcode方法 @AllArgsConstructor 会生成一个包含所有变量，同时如果变量使用了NotNull annotation ， 会进行是否为空的校验，全部参数的构造函数的自动生成，该注解的作用域也是只有在实体类上，参数的顺序与属性定义的顺序一致。 @NoArgsConstructor 无参构造函数 @RequiredArgsConstructor 会生成一个包含常量（final），和标识了@NotNull的变量 的构造方法 @NonNull 非空检查,可以帮助我们避免空指针 构造器 使用staticName启用静态工厂模式，如下所示： @RequiredArgsConstructor(staticName=”of”)。与普通构造函数不同，这种静态工厂方法将推断泛型。这意味着您的API用户可以写入MapEntry.of(“foo”, 5)而不是使用new MapEntry(“foo”, 5)。 在构造方法上添加注解。使用方法 12@RequiredArgsConstructor(onConstructor=@__(&#123;@AnnotationsGoHere&#125;))&#125;@RequiredArgsConstructor(onConstructor=@__(&#123;@Autowired&#125;))&#125; //例子 使用access标识构造器访问权限修饰符，默认为lombok.AccessLevel.PUBLIC。如： 1@AllArgsConstructor(access = lombok.AccessLevel.PROTECTED) @NoArgsConstructor(force = true)会初始化所有字段为0或者false或者null，初始化所有的参数为默认值 @val @var自动类型推断，简单来说，就是弱类型val注解变量申明是final类型 var注解变量是非final类型 @Data&emsp;&emsp;自动为所有字段添加@ToString, @EqualsAndHashCode, @Getter方法，为非final字段添加@Setter,和@RequiredArgsConstructor&emsp;&emsp;注意的是，同时使用@Data 和 @AllArgsConstructor后 ，默认的无参构造函数失效，如果需要它，要重新设置 @NoArgsConstructor @Accessors(chain = true)开启链式风格 123456789101112@Accessors(chain = true)@Setter@Getterpublic class Student &#123; private String name; private int age;&#125;Student student = new Student() .setAge(24) .setName("zs"); @Slf4j直接调用log 1log.info(xxxx); @Log使用的是 java.util.logging.Logger ，直接使用 变量 log。 @Builder使用建筑者模式构建对象。 @Cleanup自动化关闭流，相当于 jdk1.7 种的 try with resource 1234@CleanupInputStream in = new FileInputStream(args[0]);@CleanupOutputStream out = new FileOutputStream(args[1]); @SneakyThrows当我们需要抛出异常，在当前方法上调用，不用显示的在方法名后面写 throw 1@SneakyThrows(Exception.class) @Synchronized方法中所有的代码都加入到一个代码块中，默认静态方法使用的是全局锁，普通方法使用的是对象锁，当然也可以指定锁的对象。 12345private final Object lock = new Object();@Synchronized("lock")public void foo() &#123; // Do something&#125; 参考内容：&emsp;&emsp;官方文档&emsp;&emsp;你真的会写java吗?&emsp;&emsp;使用Lombok来优雅的编码]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>tools</tag>
        <tag>reconsitution</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式应用（持续更新）]]></title>
    <url>%2F2018%2F08%2F28%2Fusing%2Fregex-using%2F</url>
    <content type="text"><![CDATA[编程过程中使用的正则记录1234567891011b*[^:b#/]+.*$ 统计代码行数（不包括以# / 开头的 亦不包括空行）\d(9|[0-7])\d&#123;4&#125; 中国邮政编码^((13[0-9])|(15[^4,\\D])|(18[0,5-9]))\\d&#123;8&#125;$ 手机号^([a-z0-9A-Z]+[-|\\.]?)+[a-z0-9A-Z]@([a-z0-9A-Z]+(-[a-z0-9A-Z]+)?\\.)+[a-zA-Z]&#123;2,&#125;$ 邮箱^[\u4e00-\u9fa5]&#123;0,&#125;$ 汉字http(s)?://([\\w-]+\\.)+[\\w-]+(/[\\w- ./?%&amp;=])? url(((\d&#123;1,2&#125;)|(1\d&#123;2&#125;)|(2[0-4]\d)|(25[0-5]))\.)&#123;3&#125;((\d&#123;1,2&#125;)|(1\d&#123;2&#125;)|(2[0-4]\d)|(25[0-5])) ipv4&lt;!-&#123;2,&#125;.*-&#123;2,&#125;&gt; html注释[1-8]\d&#123;5&#125;((18)|(19)|(20))?\d&#123;2&#125;[0-1]\d[0-3]\d&#123;4&#125;[\dX]? 中华人民共和国身份证号码^[1-9]\d&#123;3&#125;-(0[1-9]|1[0-2])-(0[1-9]|[1-2][0-9]|3[0-1])$ 日期^(20|21|22|23|[0-1]\d):[0-5]\d:[0-5]\d$ 时间]]></content>
      <categories>
        <category>regular</category>
      </categories>
      <tags>
        <tag>regex</tag>
        <tag>tools</tag>
        <tag>regular</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CCNA学习笔记七 -- IPv6]]></title>
    <url>%2F2018%2F08%2F28%2Ftheory%2Fccna%2Fccna-7%2F</url>
    <content type="text"><![CDATA[DoD模型应用层 Telent、FTP、SMTP、DNS、HTTP以及其他应用协议传输层 TCP、UDP网络层 ND、MLD、ICMPv6、IPv6网络接口 各种通信网络接口（以太网等物理网络） IPv6地址（128位） 首选的格式128比特分成8段，每段的16比特用16进制表示，中间用:隔开xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx 压缩格式，允许0压缩xxxx:xxxx::xx:xxx:x:xxxx一对::在一个地址中只能出现1次 IPv4构造IPv60:0:0:0:0:0:192.168.0.1或者::192.168.0.1 子网掩码xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx/n 前n位是网络部分，后边是主机部分单播地址全球路由前缀 |子网|接口ID2001:0db8:3c4d:0012:a:d:1234:56ab链路本地地址 link local address 该地址用于同一网段中IPv6计算机通信多播地址任播地址 :: 相当于0.0.0.0::1 相当于127.0.0.12000::/3 全球单播地址范围，前三位是001FE80::/10 链路本地单播地址FF00::/8 组播地址范围3FFF:FFFF::/32 示例和文档保留地址2001:oDB8::/32 示例和文档保留地址2002::/16 用于IPv6到IPv4的转换系统 IPv6地址分配 静态 自动无状态 向路由器发送路由前缀请求，配置IPv6的路由器接口收到，然后发送路由通告，计算机获得网络部分+自己的MAC地址，进行构造IPv6地址有DHCP服务器 路由通告中M=1，则向DHCP服务器请求ip地址；路由通告中O=1，则向DHCP服务器请求其他设置如DNS服务器、搜索后缀等 123456(config)#ipv6 unicast-routing 启用IPv6(config)#interface fastEthernet 0/0(config-if)#ipv6 address 2001:13::1/64(config-if)#ipv6 nd managed-config-flag 令路由通告中M=1(config-if)#ipv6 nd other-config-flag 令路由通告中O=1 IPv6路由添加静态路由12345#show ipv6 interface fastEthernet 0/0 #show ipv6 route 查看IPv6路由表查(config)#ipv6 route 2001:1::/64 2001:1::1(config-if)#ipv6 address 2001:1::/64 eui-64 自己根据前缀和自己的MAC地址构造IPv6地址(config-if)#ipv6 address 2001:1::1/64 动态路由 RIPng协议 12345(config)#ipv6 unicast-routing(config)#ipv6 router rip 1(config-rtr)#exit(config)#interface fastEthernet 0/1(config-if)#ipv6 rip 1 enable EIGRPv6协议 1234567(config)#ipv6 unicast-routing(config)#ipv6 router eigrp 10(config-rtr)#no shutdown(config-rtr)#router-id 4.0.0.1(config-rtr)#exit(config)#interface fastEthernet 0/1(config-if)#ipv6 eigrp 10 OSPFv3协议 123456(config)#ipv6 unicast-routing(config)#ipv6 router ospf 1(config-rtr)#router-id 4.0.0.1(config-rtr)#exit(config)#interface fastEthernet 0/1(config-if)#ipv6 ospf 1 area 0 IPv4和IPv6共存技术双协议栈 IPv6 to IPv4隧道技术 1234567891011(config)#ipv6 unicast-routing(config)#interface fastEthernet 0/1(config-if)#ipv6 address 2001:1::1/64 (config-if)#exit(config)#interface tunnel 0 隧道虚拟端口(config-if)#no shutdown(config-if)#ipv6 address 2001:2::1/64 给隧道虚拟端口配置IPv6(config-if)#tunnel source 10.0.0.1 隧道源地址(config-if)#tunnel destination 10.0.1.2 隧道目标地址(config-if)#tunnel mode ipv6ip 设置隧道加密模式(config-if)#exit ISATAP隧道 配置ISATAP路由(该路由与IPv4网络接口为192.168.0.2) 123456(config)#interface tunnel 0(config-if)#ipv6 address 2001:1::/64 eui-64(config-if)#no ipv6 nd suppress-ra(config-if)#tunnel source 10.0.0.1(config-if)#tunnel mode ipv6ip isatap(config-if)#no shutdown windows下 12345&gt;netshnetsh&gt;interfacenetsh interface&gt;ipv6netsh interface ipv6&gt;isatapnetsh interface ipv6 isatap&gt;set router 192.168.0.2 静态NAT-PT 123456789(config)#interface fastEthernet 0/1(config-if)#ipv6 nat (config-if)#exit(config)#interface serial 1/0(config-if)#ipv6 nat (config-if)#exit(config)#ipv6 nat v6v4 source 10.0.0.2 2001:2::2 (config)#ipv6 nat v6v4 source 2001:2::4 10.0.0.4(config)#ipv6 prefix 2001:3::/96 动态NAT-PT 只能由IPv6网络主动向IPv4网络发起通信 12345678910111213141516(config)#interface fastEthernet 0/1(config-if)#ipv6 nat (config-if)#exit(config)#interface serial 1/0(config-if)#ipv6 nat (config-if)#exit(config)#ipv6 access-list v4map (config-ipv6-acl)#permit 2001:2::/64 any (config-ipv6-acl)#exit(config)#ipv6 access-list v6map(config-ipv6-acl)#permit 2001:2::/64 any (config-ipv6-acl)#exit(config)#ipv6 nat(config)#ipv6 nat v6v4 pool v4pool 10.0.2.100 10.0.2.200 prefix-length 24 (config)#ipv6 nat v6v4 source list v6list pool v4pool (config)#ipv6 nat prefix 2001::/96 v4-mapped v4map 2001::/96用v4map里的地址替代]]></content>
      <categories>
        <category>net</category>
      </categories>
      <tags>
        <tag>ccna</tag>
        <tag>net</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CCNA学习笔记六 -- NAT]]></title>
    <url>%2F2018%2F08%2F28%2Ftheory%2Fccna%2Fccna-6%2F</url>
    <content type="text"><![CDATA[地址转换技术 内网能够主动访问外网，外网不能主动访问内网，相对而言内网更安全一些 节省公网ip地址 缺点 慢 NAT（网络地址转换）静态NAT 动态NAT 不节省公网地址、一个公网替换一个内网地址PAT（端口地址转换） 节省公网ip、替换源端口和源地址 1#debug ip packet 开启数据包转发显示 路由器上配置PAT12345678(config)#access-list 10 permit 10.0.0.0 0.0.0.255 定义内网地址池(config)#ip nat pool name 131.107.0.1 131.107.0.1 netmask 255.255.255.0定义一个名为name的公网地址池从.0.1到.0.1(config)#ip nat inside source list 10 pool name overload 10列表绑定到name，overload表示PAT，不加overload表示NAT(config)#interface serial 0/0(config-if)#ip nat outside 0/0公网出口(config-if)#exit(config)#interface serial 0/1(config-if)#ip nat inside 0/1内网入口 端口映射 使公网地址可以访问内网地址路由端口映射1(config)#ip nat inside source static tcp 10.0.0.6 80 137.107.0.1 80 端口映射]]></content>
      <categories>
        <category>net</category>
      </categories>
      <tags>
        <tag>ccna</tag>
        <tag>net</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CCNA学习笔记五 -- ACL]]></title>
    <url>%2F2018%2F08%2F28%2Ftheory%2Fccna%2Fccna-5%2F</url>
    <content type="text"><![CDATA[网络安全物理层安全 墙上不用的网线接口，连接交换机的端口关掉数据链路层安全 ADSL拨号账号和密码 MAC地址绑定 交换机连接计算机数量控制 创建VLAN网络层安全 基于源ip地址目标IP地址的控制传输层安全 会话攻击 LAND攻击 syn洪水攻击应用层安全 登录密码 网络层安全标准的ACL 基于源地址进行控制1234567891011#config terminal (config)#access-list 10 deny host 192.168.1.2(config)#access-list 10 permit 192.168.1.0 0.0.0.255 允许192.168.1.0访问，使用翻转子网掩码(config)(config)#interface serial 3/0(config-if)#ip access-group 10 in/out 绑定控制列表到物理接口并确定出还是进检查访问列表(config)#no access-list 10 删除ACL10ACL的顺序影响访问控制扩展的ACL 基于源地址、目标地址、协议、端口号进行控制(config)#access-list 100 permit ip 192.168.1.0 0.0.0.255 any 允许192.168.1.0/24访问任何(config)#access-list 100 permit tcp 192.18.2.0 0.0.0.255 10.0.0.0 0.0.0.255 eq 80 允许192.18.2.0/24访问10.0.0.0/8上的web服务器(config)#access-list 100 permit icmp 192.18.2.0 0.0.0.255 any 允许192.18.2.0/24ping任何因特网 将acl绑定到telnet接口1(config-line)#access-class 10 in/out acl具体应用 入站————决不允许任何源地址是内部主机地址或网络地址的数据包进入一个私有的网络 12345678#access-list 150 deny ip 127.0.0.0 0.255.255.255 any log#access-list 150 deny ip 0.0.0.0 255.255.255.255 any log#access-list 150 deny ip 10.0.0.0 0.255.255.255 any log#access-list 150 deny ip 127.16.0.0 0.15.255.255 any log#access-list 150 deny ip 192.168.0.0 0.0.255.255 any log#access-list 150 deny ip 224.0.0.0 15.255.255.255 any log#access-list 150 deny ip host 255.255.255.255 any log#access-list 150 permit ip any any 出站————决不允许任何含有非内部网络有效的ip数据包出站 12#access-list 150 permit 192.168.0.0 0.0.255.255 any#access-list 150 deny ip any any log 阻塞外部访问 12#access-list 109 permit any 192.268.0.0 0.0.255.255 established #access-list 109 deny ip any any log 过滤ICMP消息————禁止ping命令进内网 #access-list 112 deny icmp any any echo log #access-list 112 deny icmp any any redirect log #access-list 112 deny icmp any any mask-request log #access-list 112 permit icmp any 192.168.0.0 0.0.255.255]]></content>
      <categories>
        <category>net</category>
      </categories>
      <tags>
        <tag>ccna</tag>
        <tag>net</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CCNA学习笔记四 -- VLAN]]></title>
    <url>%2F2018%2F08%2F28%2Ftheory%2Fccna%2Fccna-4%2F</url>
    <content type="text"><![CDATA[VLAN虚拟局域网&emsp;&emsp;VLAN是交换机组网才有的概念，按部门或管理的要求来组网，而不是按照位置组网，更灵活，安全一个VLAN=一个广播域=一个网段12345#show vlan 查看VLAN(config)#vlan 2 创建VLAN2(config)#interrface range fastEthernet 0/13 - 24 选中13-24接口(config-if-range)#switchport mode access 设置计算机接口(config-if-range)#switchport access vlan 2 设置为vlan2 单臂路由器实现VLAN间路由12(config)#interface gigabitEthernet 1/1 打开Gbit1/1接口(config-if)#switchport mode trunk 设置干道链路 三层交换机上的配置123456789(config)#ip routing 启用路由功能(config-if)#switchport trunk encapsulation dotlq设置trunk封装格式为dotlq(config-if)#switchport mode trunk(config)#Interface vlan 1(config-if)#ip address ip_address mask (config-if)# no shutdown (config)#interface vlan 2(config-if)#ip address ip_address mask (config-if)# no shutdown VTP协议123(condig)#vtp domain name 设置vtp域名(condig)#vtp password passwd 设置vtp密码(condig)#vtp mode client/server 设置客户端或者服务端，服务端可以更改整个域的VLAN的添加删除，但是不能更改其他的交换机的端口是否属于该vlan]]></content>
      <categories>
        <category>net</category>
      </categories>
      <tags>
        <tag>ccna</tag>
        <tag>net</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CCNA学习笔记三 -- 路由和交换]]></title>
    <url>%2F2018%2F08%2F28%2Ftheory%2Fccna%2Fccna-3%2F</url>
    <content type="text"><![CDATA[网络畅通的条件数据包能去能回沿途的路由器必须知道到目标地址如何转发沿途的路由器必须知道回来的数据包如何转发 路由器直连的网络 不用告诉路由器如何转发路由器没有直连的网络 管理员需要告诉路由器到目标网络如何转发 即添加静态路由123456(config)#ip route 192.168.1.0 255.255.255.0 192.268.2.0 设置数据包 到192.168.1.0/24的数据包下一跳给192.168.2.0(config)#tracroute ip_address 跟踪数据包路径#show ip route 查看路由表(config)#no ip route 192.168.1.0 255.255.255.0 删除路由表windows上添加路由表 route add ip_adress mask ip_webwindows查看路由表 netstat-r route print 动态路由优先级 直连0 静态路由1 eigp90 rip120RIP协议 跳数判断，周期性（30s）更新路由表，最大跳数16跳12345678(config)#router rip 启用rip协议 (config-router)#network 192.168.1.0 该网段参与rip协议 #debug ip rip 显示rip协议信息#undebug all 关闭rip协议信息显示#show ip protocols 显示应用协议EIGP协议 优先级高于RIP(config)#router eigp 10 启用eigp协议,相同编号路由器才可以交换路由信息(config-router)#network 192.168.1.0 该网段参与eigp协议 交换集线器 不安全、冲突域、带宽共享交换机 基于目标MAC地址转发、学习MAC地址、端口独享带宽、没有冲突、广播会出问题123456789#show mac-address-table 显示MAC地址表 #config terminal (config)#interrface fastEthernet 0/4 (config-if)#switchport mode access 接机算机的接口 (config-if)#switchport port-security 启用安全 (config-if)#switchport port-security violation shutdown 违反安全规则down掉 (config-if)#switchport port-security maxium 2 限制连接数量 (config)#interrface range fastEthernet 0/1 - 24 选中1-24个口 (config-if-range)#switchport port-security mac-adddress sticky MAC地址终止学习 生成树协议 为了高可用局域网交换机连接有了环路为了阻断网络中的广播有了生成树协议123#show spanning-tree 查看交换机端口以及生成树状态(config)#spanning-tree vlan 1 priority 4096更改路由器优先级为4096，值越小优先级越高(config)#no spanning-tree vlan 1 关闭生成树协议]]></content>
      <categories>
        <category>net</category>
      </categories>
      <tags>
        <tag>ccna</tag>
        <tag>net</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CCNA学习笔记二 -- TCP/IP协议]]></title>
    <url>%2F2018%2F08%2F27%2Ftheory%2Fccna%2Fccna-2%2F</url>
    <content type="text"><![CDATA[DoD模型应用层 Telent、FTP、SMTP、DNS、HTTP以及其他应用协议传输层 TCP、UDP网络层 IPv4、ARP、RARP、ICMP网络接口 各种通信网络接口（以太网等物理网络） 传输层协议可靠传输 TCP 分段传输 建立会话（消耗系统资源） 丢失重传不可靠传输 UDP 一个数据包就能表达完整 屏幕广播 应用层协议默认端口http=TCP+80ftp=TCP+21（接受命令、验证身份等） 20（传输数据）https=TCP+443SMTP=TCP+25（发邮件）POP3=TCP+110（收邮件）RDP=TCP+3389(远程桌面)DNS=UDP+53（DNS解析）IP地址访问Windows共享文件夹=TCP+445计算机名访问windows共享文件夹=TCP+139SQL=TCP+1433（访问数据库）telnet=TCP+23 服务和端口的关系服务侦听端口客户端请求服务 使用目标端口来区分（服务器根据数据包的目标端口来区分客户端）服务停止 侦听的端口关闭查看侦听的端口 netstat -anb|find “content”检测端口 telnet ip 端口 网络安全win2003service tcp/ip筛选不影响出去的流量wf.msc windows高级防火墙 网络层协议IP协议 选择最佳路径的协议（RIP OSPF EIGRP BGP）ICMP协议 测试网络是否畅通ping 估计带宽 查看网络是否畅通 断定远程系统 每过一个路由器TTL-1TTL 128 windows系统TTL 64 linux系统pathping 跟踪路径 计算丢包情况IGMP协议 组播点到点 广播 多播（组播）ARP协议 将计算机的IP地址解析成MAC地址数据跨网段通讯和同一网段通信过程MAC地址决定了下一跳给那个设备IP地址决定最终计算机 IP地址32位二进制组成 ip地址分类 x:network id y:host id 类别 功能 开头 个头 缺省子网掩码 A xyyy 1-127 256^3-2 255.0.0.0 B xxyy 128-191 256^2-2 255.255.0.0 C xxxy 192-223 256-2 255.255.255.0 D 组播 224-239 E 研究 240-255 保留的私网地址A 10.0.0.0B 172.16.0.0-172.31.0.0C 192.168.0.0-192.168.255.0 本地环回地址127.0.0.1 ping通过表示TCP/IP协议安装正常169.254.0.0 DHCP获取网络地址未果的时候得到的地址]]></content>
      <categories>
        <category>net</category>
      </categories>
      <tags>
        <tag>ccna</tag>
        <tag>net</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CCNA学习笔记一 -- 计算机网络详解]]></title>
    <url>%2F2018%2F08%2F27%2Ftheory%2Fccna%2Fccna-1%2F</url>
    <content type="text"><![CDATA[局域网与广域网 局域网 自己花钱买设备自己搭配服务器，带宽固定 广域网 花钱租带宽 OSI参考模型↑7 应用层 能产生网络流量的应用程序 ↑6 表示层 表示数据，处理数据 加密 压缩 等 ↑5 会话层 msconfig netstat -nb (显示程序) ↑4 传输层 可靠传输 建立会话 流量控制 差错检查 不可靠传输 不建立会话 节省服务器资源 ↑3 网络层 选择最佳路径 ↑2 数据链路层 网络设备 如何封装数据帧 设备地址 ↑1 物理层 规定了电压标准、接口标准 程序员的工作层 应用层、表示层、会话层网络工程师的工作层 传输层、网络层、数据链路层、物理层网络分层的好处：每一层互不干扰，没有影响；有主于设备标准化 网络排错和OSI参考模型 网络层 可能出现的错误 物理层 连接问题 数据链路层 MAC地址冲突 ADSL拨号密码错误 网络层 计算机网关设置错误、路由器路由表错误 应用层 IE代理设置错误 网络安全和OSI参考模型 网络层 安全问题 物理层安全 数据链路层安全 MAC地址认证 ADSL拨号上网账号密码 划分VLAN 网络层安全 路由器ACL 传输层安全 计算机端口安全 应用层安全 网站安全、操作系统安全 网络设备 网线双绞线 4对 8根 100米 10M 100M（实际用了4根） 1000M （实际用了8根）线序 直通线（都按B连） 同类设备用交叉线（一个A 一个B）不同类设备用直通线水晶头接法 RJ45 A 绿白 绿 橙白 蓝 蓝白 橙 棕白 棕 RJ45 B 橙白 橙 绿白 蓝 蓝白 绿 棕白 棕 网卡 MAC地址（物理地址）不能更改MAC地址由48位二进制组成，前24位代表厂家 后边为厂家自己所设置的序号查看MAC地址的指令（dos下） ipconfig /all 集线器 HUB 不安全 带宽共享 效率低下 半双工 网桥 隔绝冲突域 交换机 基于MAC地址转发数据、带宽独享、全双工、安全、学习MAC地址 路由器 负责在不同网段转发数据 一般有广域网接口 隔绝广播（MAC地址全1） 网络设备和OSI参考模型集线器 物理层设备交换机 基于MAC地址转发 数据链路层设备路由器 基于IP地址转发 三层设备 分层考虑问题网络排错方法 替换法]]></content>
      <categories>
        <category>net</category>
      </categories>
      <tags>
        <tag>ccna</tag>
        <tag>net</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Regular Expression 正则表达式]]></title>
    <url>%2F2018%2F08%2F25%2Ftheory%2Fregex%2F</url>
    <content type="text"><![CDATA[Regular Expression（正则表达式） 简称Regex在Javascript中 g(global)表示全局 i表示不区分大小写 .可以匹配任何一个单位的字符 []用于定义字符集合 ^取非 元字符 元字符 解释说明 [\b] Backspace键（退格) \n 换行符 \f 换页符 \r 回车符 \t 制表符（tab） \v 垂直制表符 \r\n 回车+换行 许多操作系统以此为行结束，Unix与Linux以\n作为行结束 \d 任何一个数字字符 [0-9] \D 任何一个非数字字符 0-9 \w [a-zA-Z0-9_] \W a-zA-Z0-9_ \s [\f\n\r\t\v] 任一一个空白字符 \S \f\n\r\t\v 任一一个非空白字符 \xXX XX:表示十六进制数 \0XX XX:表示八进制数 POSIX字符类 javascript不支持 POSIX字符类 解释说明 [:alnum:] [\w^_] [:upper:] [A-Z] [:alpha:] [a-zA-Z] [:blank:] [ \t] 注意：这里包含空格 [:xdigit:] 任何一个十六进制数 [a-fA-F0-9] [:cntrl:] ASCII控制字符 0-31加上127 [:digit:] \d [:graph:] [:print:]去除空格 [:lower:] [a-z] [:print:] 任何一个可打印字符 [:punct:] 既不属于[:alnum:]也不属于[:cntrl:]的字符 [:space:] [\f\r\n\t\v ] 注意：这里包含空格 符号 解释说明 + 一次或多次重复 +? 懒惰型 * 零次或多次重复 *? 懒惰型 ? 零次或一次出现 \{n\} 重复n次 \{m,n\} 至少m次，至多n次 \{m,\} 至少出现m次 \{m,\}? 懒惰型 \b 一个单词的开头或结尾 b：boundary \B 不匹配一个单词边界 ^ 字符串开头 $ 字符串结尾 (?m) 置于开头，用于开启分行匹配模式 multline mode 注意：有的语言不支持 (xx) 子表达式，视为独立元素 回溯引用 backreference替换模式下Javascript使用$代替\ 符号 解释说明 \1,\2……\n 第1个表达式，第2个表达式…….第n个表达式 \0 代表整个正则表达式 \E 结束 \L或\U转换 \l 把下一个字符转换为小写 \L 把\L到\E之间全部转换为小写 \u 把下一个字符转换为大写 \U 把\U到\E之间全部转换为大写 注意：1、 Java、Perl、PHP、.NET 支持向后查找2、 Javascript、ColdFusion 不支持向后查找向前查找：(?=x) 匹配但不消费x，即结果不包括x 例 (?=:) 原字符串 https: 匹配结果 http向后查找：(?&lt;=x) 匹配但不消费x，即结果不包括x 例 (?&lt;=$) 原字符串 $400 匹配结果 400注意：向前查找可以任意长度（可以使用.+） 向后查找的长度是固定的 (?=) 正向前查找 (?&lt;=) 正向后查找 (?!) 负向前查找 (?&lt;!) 负向后查找 Mysql JAVA1.4不支持条件处理(?(backreference)true-regex)(?(backreference)true-regex|false-regex)Backreference满足时，匹配true-regex 否则匹配false-regex]]></content>
      <categories>
        <category>regular</category>
      </categories>
      <tags>
        <tag>code</tag>
        <tag>regex</tag>
        <tag>tools</tag>
        <tag>regular</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git命令]]></title>
    <url>%2F2018%2F08%2F25%2Fusing%2FGit%2F</url>
    <content type="text"><![CDATA[查看、添加、提交、删除、找回，重置修改文件git help \ # 显示command的helpgit show # 显示某次提交的内容 git show $idgit co — \ # 抛弃工作区修改git co . # 抛弃工作区修改git add \ # 将工作文件修改提交到本地暂存区git add . # 将所有修改过的工作文件提交暂存区git rm \ # 从版本库中删除文件git rm \ —cached # 从版本库中删除文件，但不删除文件git reset \ # 从暂存区恢复到工作文件git reset — . # 从暂存区恢复到工作文件git reset —hard # 恢复最近一次提交过的状态，即放弃上次提交后的所有本次修改git ci \ git ci . git ci -a # 将git add, git rm和git ci等操作都合并在一起做git ci -am “some comments”git ci —amend # 修改最后一次提交记录git revert \&lt;$id&gt; # 恢复某次提交的状态，恢复动作本身也创建次提交对象git revert HEAD # 恢复最后一次提交的状态 查看文件diffgit diff \ # 比较当前文件和暂存区文件差异 git diffgit diff \\\ # 比较两次提交之间的差异git diff \..\ # 在两个分支之间比较git diff —staged # 比较暂存区和版本库差异git diff —cached # 比较暂存区和版本库差异git diff —stat # 仅仅比较统计信息 查看提交记录git log git log \ # 查看该文件每次提交记录git log -p \ # 查看每次详细修改内容的diffgit log -p -2 # 查看最近两次详细修改内容的diffgit log —stat #查看提交统计信息tig Mac上可以使用tig代替diff和log，brew install tig Git 本地分支管理 查看、切换、创建和删除分支git br -r # 查看远程分支git br \ # 创建新的分支git br -v # 查看各个分支最后提交信息git br —merged # 查看已经被合并到当前分支的分支git br —no-merged # 查看尚未被合并到当前分支的分支git co \ # 切换到某个分支git co -b \ # 创建新的分支，并且切换过去git co -b \ \ # 基于branch创建新的new_branchgit co $id # 把某次历史提交记录checkout出来，但无分支信息，切换到其他分支会自动删除git co $id -b \ # 把某次历史提交记录checkout出来，创建成一个分支git br -d \ # 删除某个分支git br -D \ # 强制删除某个分支 (未被合并的分支被删除的时候需要强制) 分支合并和rebasegit merge \ # 将branch分支合并到当前分支git merge origin/master —no-ff # 不要Fast-Foward合并，这样可以生成merge提交git rebase master \ # 将master rebase到branch，相当于： git co \ &amp;&amp; git rebase master &amp;&amp; git co master &amp;&amp; git merge \ Git补丁管理(方便在多台机器上开发同步时用)git diff &gt; ../sync.patch # 生成补丁git apply ../sync.patch # 打补丁git apply —check ../sync.patch #测试补丁能否成功 Git暂存管理git stash # 暂存git stash list # 列所有stashgit stash apply # 恢复暂存的内容git stash drop # 删除暂存区 Git远程分支管理git pull # 抓取远程仓库所有分支更新并合并到本地git pull —no-ff # 抓取远程仓库所有分支更新并合并到本地，不要快进合并git fetch origin # 抓取远程仓库更新git merge origin/master # 将远程主分支合并到本地当前分支git co —track origin/branch # 跟踪某个远程分支创建相应的本地分支git co -b \ origin/\ # 基于远程分支创建本地分支，功能同上git push # push所有分支git push origin master # 将本地主分支推到远程主分支git push -u origin master # 将本地主分支推到远程(如无远程主分支则创建，用于初始化远程仓库)git push origin \ # 创建远程分支， origin是远程仓库名git push origin \:\ # 创建远程分支git push origin :\ #先删除本地分支(git br -d \)，然后再push删除远程分支 Git远程仓库管理GitHubgit remote -v # 查看远程服务器地址和仓库名称git remote show origin # 查看远程服务器仓库状态git remote add origin git@github:robbin/robbin_site.git # 添加远程仓库地址git remote set-url origin git@github.com:robbin/robbin_site.git # 设置远程仓库地址(用于修改远程仓库地址) git remote rm \ # 删除远程仓库 创建远程仓库git clone —bare robbin_site robbin_site.git # 用带版本的项目创建纯版本仓库scp -r my_project.git git@ git.csdn.net:~ # 将纯仓库上传到服务器上mkdir robbin_site.git &amp;&amp; cd robbin_site.git &amp;&amp; git —bare init # 在服务器创建纯仓库git remote add origin git@github.com:robbin/robbin_site.git # 设置远程仓库地址git push -u origin master # 客户端首次提交git push -u origin develop # 首次将本地develop分支提交到远程develop分支，并且trackgit remote set-head origin master # 设置远程仓库的HEAD指向master分支 ，也可以命令设置跟踪远程库和本地库git branch —set-upstream master origin/mastergit branch —set-upstream develop origin/develop refloggit reflog是对reflog进行管理的命令,reflog是git用来记录引用变化的一种机制,比如记录分支的变化或者是HEAD引用的变化.当git reflog不指定引用的时候,默认列出HEAD的reflog.HEAD@{0}代表HEAD当前的值,HEAD@{3}代表HEAD在3次变化之前的值.git会将变化记录到HEAD对应的reflog文件中,其路径为.git/logs/HEAD, 分支的reflog文件都放在.git/logs/refs目录下的子目录中. 特殊符号^代表父提交,当一个提交有多个父提交时,可以通过在^后面跟上一个数字,表示第几个父提交: ^相当于^1.~\相当于连续的\个^.]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>tools</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx的使用（一）-- 简单的安装使用]]></title>
    <url>%2F2018%2F08%2F25%2Fusing%2Fmiddleware%2Fnginx-1%2F</url>
    <content type="text"><![CDATA[一、nginx简介1、nginx是什么Nginx (engine x) 是一个高性能的HTTP和反向代理服务，也是一个IMAP/POP3/SMTP服务。其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好。 2、nginx可以用来做什么（不加载第三方模块） 反向代理 负载均衡 HTTP服务器（包含动静分离） 正向代理 缓存 二、nginx安装以及简单的配置1、安装nginx（环境 centos7）采取最简单的方法，yum install nginx -y 2、配置nginx① 修改user为root（你用来启动nginx的账户）② 添加转发服务器123456789101112131415161718192021222324252627upstream web_server&#123; # 名字随便起 server 127.0.0.1:8080 max_fails=1 fail_timeout=10s; #Tomcat服务器1 ip server 127.0.0.2:8080 max_fails=1 fail_timeout=10s; #Tomcat服务器2 ip #注意服务器的ip以及端口不要重复 ...&#125;server &#123; listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/html; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; proxy_pass http://web_server; #和上边定义的upstream 对应起来 proxy_connect_timeout 10; proxy_read_timeout 10; proxy_send_timeout 10; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125;&#125; 3、nginx的启动、停止、重启1234systemctl start nginx #启动nginxsystemctl stop nginx #停止nginxsystemctl restart nginx #重新启动nginxsystemctl enable nginx #开机启动nginx 4、nginx踩过的一些坑selinux引起的权限访问受限问题，cat /var/log/Audit/Audit.log 发现有nginx访问阻止记录1type=AVC msg=audit(1416406823.013:3137): avc: denied &#123; search &#125; for pid=15488 comm="nginx" name="www" dev="dm-3" ino=146 scontext=system_u:system_r:httpd_t:s0 tcontext=unconfined_u:object_r:user_home_dir_t:s0 tclass=dir 解决方案1、（建议采用）设置selinux允许nginx123yum install policycoreutils-pythoncat /var/log/audit/audit.log | grep nginx | grep denied | audit2allow -M mynginxsemodule -i mynginx.pp 解决方案2.1、临时关闭selinux1setenforce 0 #重启后失效 解决方案2.2、永久关闭selinux 打开 selinux 配置文件1vim /etc/selinux/config 修改 selinux 配置文件将SELINUX=enforcing改为SELINUX=disabled，保存后退出1234567891011# This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=enforcing# SELINUXTYPE= can take one of three two values:# targeted - Targeted processes are protected,# minimum - Modification of targeted policy. Only selected processes are protected.# mls - Multi Level Security protection.SELINUXTYPE=targeted 重启电脑（一定重启，否则无效）]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
</search>
